# Java基础



## 面向对象四大特性:封装，继承，多态，抽象

1. **`封装`**就是`将类的信息隐藏在类内部，不允许外部程序直接访问`，而是通过该类的方法实现对隐藏信息的操作和访问。良好的封装能够减少耦合。
2. **`继承`**是从已有的类中派生出新的类，`新的类继承父类的属性和行为`，并能扩展新的能力，大大增加程序的重用性和易维护性。在J`ava中是单继承`的，也就是说一个子类只有一个父类。
3. **`多态`**是`同一个行为具有多个不同表现形式的能力`。在不修改程序代码的情况下改变程序运行时绑定的代码。`实现多态的三要素:继承、重写、父类引用指向子类对象。`
   - `静态多态性`:通过`重载`实现，相同的方法有不同的参数列表，可以根据参数的不同，做出不同的处理。
   - `动态多态性`:在子类中`重写`父类的方法。运行期间判断所引用对象的实际类型，根据其实际类型调用相应的方法。
4. **`抽象`**：把客观事物用代码抽象出来。

## 为什么建议使用 BigDecimal 进行浮点数运算？

- 浮点数缺点：计算机是二进制的，而且计算机在表示一个数字时，`宽度是有限`的，`无限循环的小数`存储在计算机时，只能被`截断`，所以就会导致小数精度发生损失的情况->`十进制下的 0.2 就没办法精确转换成二进制小数`
- **浮点数之间的等值判断，基本数据类型不能用 == 来比较，包装数据类型不能用 equals 来判断。**

```java
BigDecimal a = new BigDecimal("1.0");
BigDecimal b = new BigDecimal("0.9");
BigDecimal c = new BigDecimal("0.8");

BigDecimal x = a.subtract(b);
BigDecimal y = b.subtract(c);

System.out.println(x.compareTo(y));// 0
```

- BigDecimal`加减乘除`：**`add`** 方法用于将两个 `BigDecimal` 对象相加，**`subtract`** 方法用于将两个 `BigDecimal` 对象相减。**`multiply`** 方法用于将两个 `BigDecimal` 对象相乘，**`divide`** 方法用于将两个 `BigDecimal` 对象相除。
- 大小比较：`x.compareTo(y)`;`equals()` 方法不仅仅会比较值的大小（value）还`会比较精度`（scale);而 `compareTo()` 方法比较的时候会`忽略精度`。
- 保留小数：

```java
BigDecimal m = new BigDecimal("1.255433");
BigDecimal n = m.setScale(3,RoundingMode.HALF_DOWN);
System.out.println(n);// 1.255
```

## == 和 equals() 的区别

**`==`** 对于基本类型和引用类型的作用效果是不同的：

- 对于基本数据类型来说，`==` 比较的是值。
- 对于引用数据类型来说，`==` 比较的是对象的内存地址。

> 因为 Java 只有值传递，所以，对于 == 来说，不管是比较基本数据类型，还是引用数据类型的变量，其本质比较的都是值，只是引用类型变量存的值是对象的地址。

**`equals()`** 不能用于判断基本数据类型的变量，只能用来判断两个对象是否相等。`equals()`方法存在于`Object`类中，而`Object`类是所有类的直接或间接父类，因此所有的类都有`equals()`方法。

`Object` 类 `equals()` 方法：

```java
public boolean equals(Object obj) {
     return (this == obj);
}
```

`equals()` 方法存在两种使用情况：

- **类没有重写 `equals()`方法** ：通过`equals()`比较该类的两个对象时，等价于通过“==”比较这两个对象，使用的默认是 `Object`类`equals()`方法。
- **类重写了 `equals()`方法** ：一般我们都重写 `equals()`方法来比较两个对象中的属性是否相等；若它们的属性相等，则返回 true(即，认为这两个对象相等)。
- `String` 中的 `equals` 方法是被重写过的，因为 `Object` 的 `equals` 方法是比较的对象的内存地址，而 `String` 的 `equals` 方法比较的是对象的值

## 什么是值传递和引用传递?

- `值传递`是对基本型变量而言的，传递的是该变量的一个副本，`改变副本不影响原变量`。
- `引用传递`一般是对于对象型变量而言的，传递的是该对象地址的一个副本，并不是原对象本身，`两者指向同一片内存空间`。所以`对引用对象进行操作会同时改变原对象。`
- `java中不存在引用传递，只有值传递`。即不存在变量a指向变量b，变量b指向对象的这种情况。

## String为什么不可变？

`理由：`

1. 保存字符串的数组被 `final` 修饰且为私有的，并且`String` 类没有提供/暴露修改这个字符串的方法。
2. `String` 类被 `final` 修饰导致其不能被继承，进而避免了子类破坏 `String` 不可变。

- `线程安全`：同一个字符串实例可以被多个线程共享，因为字符串不可变，本身就是线程安全的。

- `支持hash映射和缓存`。因为String的hash值经常会使用到，比如作为Map的键，不可变的特性使得hash 值也不会变，**不需要重新Hash**。

- `出于安全考虑`：网络地址URL、文件路径path、密码通常情况下都是以string类型保存，假若String不是固定不变的，将会引起各种安全隐患。比如将密码用String的类型保存，那么它将一直留在内存中，直到垃圾收集器把它清除。假如String类不是固定不变的，那么这个密码可能会被改变，导致出现安全隐患。
- `字符串常量池优化`：String对象创建之后，会缓存到字符串常量池中，下次需要创建同样的对象时，可以直接返回缓存的引用。

## String, StringBuffer和StringBuilder区别

1. `可变性`

- String 不可变

- StringBuffer和StringBuilder可变

2. `线程安全`

- String 不可变，因此是线程安全的StringBuilder不是线程安全的
- StringBuffer是线程安全的，内部使用synchronized进行同步

## Object常用方法？

- `tostring()`：`默认输出对象地址`，可以重写，按照重写逻辑输出对象值；
- `equals()`：默认比较两个引用变量`是否指向同一个对象（内存地址）`；
- `hashcode()`：将与对象相关的信息映射成一个哈希值，默认的实现hashCode值是`根据内存地址换算出来`；
- `clone()`：`Java赋值是复制对象引用`，如果我们想要得到一个对象的副本，使用赋值操作是无法达到目的的。clone()方法，`实现了对象中各个属性的复制`，但它的`可见范围是protected（被protected修饰的成员对于本包和其子类可见）`的。

## 讲讲深拷贝和浅拷贝？

Cat类 其中有Person对象，调用clone()的例子

- **`浅拷贝`**：`浅拷贝会在堆上创建一个新的对象`（区别于`引用拷贝`的一点），不过，如果原对象内部的属性是引用类型的话，`浅拷贝会直接复制内部对象的引用地址`，也就是说`拷贝对象和原对象共用同一个内部对象`。
- **`深拷贝`** ：深拷贝会`完全复制`整个对象，`包括这个对象所包含的内部对象`。

- `引用拷贝`：`两个不同的引用指向同一个对象`

![浅拷贝、深拷贝、引用拷贝示意图](D:\算法Typora\picture\shallow&deep-copy.png)

## Java创建对象有几种方式？

- 用`new语句创建`对象。

- 使用`反射`，使用`Class.newlnstance()`创建对象。

- 调用对象的`clone()方法`。

- 运用`反序列化手段`，调用`java.io.ObjectInputStream`对象的`readObject()`方法。

## 构造方法有哪些特点？是否可被 override?

构造方法特点如下：

- **名字与类名相同**。
- **没有返回值**，但不能用 void 声明构造函数。
- 生成类的对象时自动执行，**无需调用**。

`构造方法`不能被 override（重写）,但是`可以 overload（重载）`,所以你可以看到`一个类中有多个构造函数`的情况

## 接口和抽象类有什么共同点和区别？

**共同点** ：

- 都`不能被实例化。`
- 都`可以包含抽象方法`。
- 都可以有`默认实现的方法`（Java 8 可以用 `default` 关键字在接口中定义默认方法）。

**区别** ：

- `接口主要用于对类的行为进行约束`，你实现了某个接口就具有了对应的行为。`抽象类主要用于代码复用，强调的是所属关系`。
- 一个类只能继承一个类，但是可以实现多个接口。
- 接口中的成员变量只能是 `public static final` 类型的，不能被修改且必须有初始值，而抽象类的成员变量默认 default，可在子类中被重新定义，也可被重新赋值。

## ===========================**异常类层次结构图概览**==========================

<img src="D:\算法Typora\picture\types-of-exceptions-in-java.png" alt="Java 异常类层次结构图" style="zoom: 67%;" />

## 常见的Exception有哪些？

1. 常见的RuntimeException：
   - `classcastException`->类型转换异常
   - `IndexoutofBoundsException`->数组越界异常
   - `NullPointerException`->空指针
   - `ArrayStoreException`->数组存储异常
   - `NumberFormatException`->数字格式化异常
   - `ArithmeticException`->数学运算异常
2. unchecked Exception:
   - `NoSuchFieldException`->反射异常，没有对应的字段
   - `classNotFoundException`->类没有找到异常
   - `IllegalAccessException`->安全权限异常，可能是反射时调用了private方法

## Error和Exception的区别？

在 Java 中，所有的异常都有一个共同的祖先 `java.lang` 包中的 `Throwable` 类。`Throwable` 类有两个重要的子类:

- **`Exception`** :`程序本身可以处理的异常`，可以通过 `catch` 来进行捕获。`Exception` 又可以分为 Checked Exception (受检查异常，必须处理) 和 Unchecked Exception (不受检查异常，可以不处理)。
- **`Error`** ：`Error` 属于`程序无法处理`的错误 ，不建议通过`catch`捕获 。例如 Java 虚拟机运行错误（`Virtual MachineError`）、虚拟机内存不够错误(`OutOfMemoryError`)、类定义错误（`NoClassDefFoundError`）等 。这些异常发生时，Java 虚拟机（JVM）一般会选择线程终止。

## 反射是什么？优缺点？应用场景？

- 反射之所以被称为`框架的灵魂`，主要是因为它赋予了我们`在运行时分析类以及执行类中方法的能力`。通过反射你可以获取任意一个类的所有属性和方法，你还可以调用这些方法和属性。
- 优点：可以让我们的`代码更加灵活`、为各种框架提供开箱即用的功能提供了便利；
- 缺点：增加了`安全问题`，比如可以无视泛型参数的安全检查；反射的性能也要稍差点；
- **框架中也大量使用了动态代理，而动态代理的实现也依赖反射**

## 获取Class对象的四种方式？

**1. `知道具体类`的情况下可以使用：**

```java
Class alunbarClass = TargetObject.class;
```

但是我们一般是不知道具体类的，基本都是通过遍历包下面的类来获取 Class 对象，通过此方式获取 Class 对象不会进行初始化

**2. 通过 `Class.forName()`传入类的全路径获取：**

```java
Class alunbarClass1 = Class.forName("cn.javaguide.TargetObject");
```

**3. 通过对象实例`instance.getClass()`获取：**

```java
TargetObject o = new TargetObject();
Class alunbarClass2 = o.getClass();
```

**4. 通过类加载器`xxxClassLoader.loadClass()`传入类路径获取:**

```java
ClassLoader.getSystemClassLoader().loadClass("cn.javaguide.TargetObject");
```

通过类加载器获取 Class 对象不会进行初始化，意味着不进行包括初始化等一系列步骤，静态代码块和静态对象不会得到执行



## 同步阻塞IO、同步非阻塞IO、异步非阻塞IO？

- `同步阻塞IO`∶用户进程发起一个IO操作以后，必须等待IO操作的真正完成后，才能继续运行。
- `同步非阻塞IO`:客户端与服务器通过Channel连接，采用`多路复用器轮询注册的channe`l。提高吞吐量和可靠性。用户进程发起一个IO操作以后，可做其它事情，但用`户进程需要轮询IO操作是否完成`，这样`造成不必要的CPU资源浪费`。
- `异步非阻塞IO`:非阻塞异步通信模式，NIO的升级版，采用异步通道实现异步通信，其read和write方法均是异步方法。`用户进程发起一个IO操作，然后立即返回，等IO操作真正的完成以后，应用程序会得到IO操作完成的通知`。类似Future模式。

## Java8新特性有哪些？

- `Lambda表达式`: Lambda允许把函数作为一个方法的参数
- `Stream API`∶新添加的Stream API (`java.util.stream`）把真正的函数式编程风格引入到Java中
- `默认方法`:默认方法就是一个`在接口里面有了一个实现的方法`。
- `Optional类`:Optional类已经成为Java8类库的一部分，`用来解决空指针异常`。
- `Date Time` API:加强对日期与时间的处理。

## 手动实现序列化和反序列化？

### 1、序列化

📕：Java中的序列化机制能够将一个实例对象（`只序列化对象的属性值`，而不会去序列化什么所谓的方法。）的`状态信息写入到一个字节流中`使其可以`通过socket进行传输`、或者`持久化到存储数据库或文件系统中`；然后在`需要的时候通过字节流中的信息来重构一个相同的对象`。

实现`Serializable接口`+使用`ObjectOutputStream`

```Java
import java.io.Serializable; 
@DATA
public class Person implements Serializable{}

import java.io.File;
import java.io.FileOutputStream; 
import java.io.ObjectOutputStream ;
public class ObjectOutputStreamDemo
{
    //序列化 
    public static void main(String[] args) throws Exception 
    {
        //序列化后生成指定文件路径 
        File file = new File("D:" + File.separator + "person.ser") ;
        ObjectOutputStream oos = null ;
        //装饰流（流）
        oos = new ObjectOutputStream(new FileOutputStream(file)) ; 
        //实例化类 
        Person per = new Person("张三",30) ;
        oos.writeObject(per) ;
        //把类对象序列化
        oos.close() ;
    } 
}
```

### 2、反序列化（`ObjectInputStream`）->`stream.readObject()`

```java
import java.io.FileInputStream;
import java.io.IOException;
import java.io.ObjectInputStream;
public class Test01 {
    public static void main(String[] args) {
        ObjectInputStream ois=null;
        //反序列化
        try {
            //这个Users是文件的名称（位置在项目根路径下）
            ois=new ObjectInputStream(new FileInputStream("Users"));
            //读
            Object obj=ois.readObject();
            //输出
            System.out.println(obj);
        } catch (IOException e) {
            e.printStackTrace();
        } catch (ClassNotFoundException e) {
            e.printStackTrace();
        }finally {
            //关闭
            try {
                ois.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}
```

📕：对于`不想进行序列化`的变量，使用 `transient` 关键字修饰。

- `transient` 只能修饰变量，不能修饰类和方法。
- `transient` 修饰的变量，在反序列化后变量值将会被置成类型的默认值。例如，如果是修饰 `int` 类型，那么反序列后结果就是 `0`。
- `static` 变量因为不属于任何对象(Object)，所以无论有没有 `transient` 关键字修饰，均不会被序列化。

##  Java IO 流了解吗？I/O 流为什么要分为字节流和字符流呢?

- IO 流在 Java 中分为`输入流和输出流`，而根据数据的处理方式又分为`字节流和字符流`。

- Java IO 流的 40 多个类都是从如下 4 个抽象类基类中派生出来的。

  - `InputStream`/`Reader`:前者是字节输入流（`用于读取原始字节`），后者是字符输入流（`用于读取文本`）。

  - `OutputStream`/`Writer`:前者是字节输出流，后者是字符输出流。

- IO 操作是很消耗性能的，缓冲流将数据加载至缓冲区，`一次性读取/写入多个字节`，从而避免频繁的 IO 操作，提高流的传输效率。

- 字节缓冲流这里采用了`装饰器模式`来增强 `InputStream` 和`OutputStream`子类对象的功能。

- 举个例子，我们可以通过 `BufferedInputStream`（字节缓冲输入流）来增强 `FileInputStream` 的功能。

## 单例模式有哪几种写法？应用场景？优缺点？

参考url：https://blog.csdn.net/weixin_45526437/article/details/124702055

单例模式（`Singleton Pattern`）是 Java 中最简单的设计模式之一。这种类型的设计模式`属于创建型模式`，它提供了一种创建对象的最佳方式。

- 单例模式`只能有一个实例对象`
- 单例类必须`自己创建`自己的唯一实例。
- 单例类必须`给所有其他对象提供`这一实例。

### 1、种类

单例模式共有5种创建方式，分别为：

- **`饿汉式`****
- **`DCL懒汉式`**
- **`双检锁懒汉式`**
- `**Enum枚举饿汉式`**
- **`内部类懒汉式`**

项目中`对于全局唯一的对象将其封装为单例模式`，`开箱即用`，非常方便；

### 2、应用场景

单例模式经常用在`需要一个实例的程序`中，例如

- `Spring框架IOC容器`就使用到了单例模式，默认创建对象的时候为单例模式

- `ResultBean 后端`统一返回给前端的封装类，这个在项目中是唯一的，`只用一个对象进行返回JSON给前端`进行渲染

`JDK中`也有单例模式的身影，例

- Runtime 体现了饿汉式单例
- Console 体现了双检锁懒汉式单例
- Collections 中的 EmptyNavigableSet 内部类懒汉式单例

### 3、单例模式的优缺点

**优点**

1. 提供了对**`唯一实例的访问`**
2. 可以**节约系统资源，提高系统的性能，`减少不必要的内存开销`**
3. 允许**可变数目的实例（`多例类`）**

**缺点**

1. **`扩展困难`**（缺少抽象层）
2. 单例类的**`职责过重`**
3. 由于`自动垃圾回收机制`，可能会导致`共享的单例对象的状态丢失`

### 4、手写双重检测锁懒汉单例

```java
//单例
public class Singleton { 
  private volatile Singleton instance = null; //volatile禁止JVM指令重排，保证 new Singleton()的3步指令有序执行
  public Singleton getInstance() { 
    if (instance == null) { 
      synchronized(this) { 
        if (instance == null) { 
            //new 分3步
            //1、分配空间，给对象找内存
            //2、创建对象，给成员变量赋初始值
            //3、引用赋值 
            // JVM可能对这三步进行重排
          instance = new Singleton(); 
        } 
      } 
    } 
    return instance; 
  } 
}
```




# 集合

## 概览：

Java 集合， 也叫作容器，主要是由两大接口派生而来：一个是 `Collection`接口，主要用于存放单一元素；另一个是 `Map` 接口，主要用于存放键值对。对于`Collection` 接口，下面又有三个主要的子接口：`List`、`Set` 和 `Queue`。

![img](D:\算法Typora\picture\java-collection-hierarchy.png)

## 集合框架底层数据结构总结

#### [#](https://javaguide.cn/java/collection/java-collection-questions-01.html#list)List

- `ArrayList`： `Object[]` 数组
- `Vector`：`Object[]` 数组
- `LinkedList`： 双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环)

#### [#](https://javaguide.cn/java/collection/java-collection-questions-01.html#set)Set

- `HashSet`(无序，唯一): 基于 `HashMap` 实现的，底层采用 `HashMap` 来保存元素
- `LinkedHashSet`: `LinkedHashSet` 是 `HashSet` 的子类，并且其内部是通过 `LinkedHashMap` 来实现的。有点类似于我们之前说的 `LinkedHashMap` 其内部是基于 `HashMap` 实现一样，不过还是有一点点区别的
- `TreeSet`(有序，唯一): 红黑树(自平衡的排序二叉树)

#### [#](https://javaguide.cn/java/collection/java-collection-questions-01.html#queue)Queue

- `PriorityQueue`: `Object[]` 数组来实现二叉堆
- `ArrayQueue`: `Object[]` 数组 + 双指针

再来看看 `Map` 接口下面的集合。

#### [#](https://javaguide.cn/java/collection/java-collection-questions-01.html#map)Map

- `HashMap`： JDK1.8 之前 `HashMap` 由数组+链表组成的，数组是 `HashMap` 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间
- `LinkedHashMap`： `LinkedHashMap` 继承自 `HashMap`，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，`LinkedHashMap` 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。详细可以查看：[《LinkedHashMap 源码详细分析（JDK1.8）》open in new window](https://www.imooc.com/article/22931)
- `Hashtable`： 数组+链表组成的，数组是 `Hashtable` 的主体，链表则是主要为了解决哈希冲突而存在的
- `TreeMap`： 红黑树（自平衡的排序二叉树）

## ArrayList和LinkedList区别

- 首先，他们的底层数据结构不同，`ArrayList底层是基于动态数组`实现的，`LinkedList底层是基于链表`实现的
- 由于底层数据结构不同，他们所适⽤的场景也不同，`ArrayList更适合随机查找`，`LinkedList更适合删除和添加`，查询、添加、删除的时间复杂度不同
- 另外ArrayList和LinkedList`都实现了List接口`，但是`LinkedList还额外实现了Deque接口`，所以 LinkedList还可以当做队列来使用；
- 我们在项目中一般是不会使用到 `LinkedList` 的，需要用到 `LinkedList` 的场景几乎都可以使用 `ArrayList` 来代替，并且，性能通常会更好！就连 `LinkedList` 的作者约书亚 · 布洛克（Josh Bloch）自己都说从来不会使用 `LinkedList`
  

## ArrayList扩容机制

ArrayList：

```java
public class ArrayList<E> extends AbstractList<E>
        implements List<E>, RandomAccess, Cloneable, java.io.Serializable{
  }
```

ArrayList扩容的本质就是计算出新的扩容数组的size后实例化，并将原有数组内容复制到新数组中去。默认情况下,`DEFAULT_CAPACITY = 10`，新的容量会是`原容量的1.5倍`；

```java
    private Object[] grow(int minCapacity) {
        int oldCapacity = elementData.length;//获取原数组长度
        if (oldCapacity > 0 || elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
            int newCapacity = ArraysSupport.newLength(oldCapacity,
                    minCapacity - oldCapacity, /* minimum growth */
                    oldCapacity >> 1           /* preferred growth */);
            return elementData = Arrays.copyOf(elementData, newCapacity);
        } else {
            return elementData = new Object[Math.max(DEFAULT_CAPACITY, minCapacity)];
        }
    }
	int prefLength = oldLength + Math.max(minGrowth, prefGrowth); // might overflow
```

📕：补充

怎么`遍历ArrayList时移除一个元素`？（for-each会报错）

```java
        List<Integer> list = new ArrayList<>();
        Iterator<Integer> iterator = list.iterator();//使用迭代器
        while(iterator.hasNext()){
            if (iterator.next().equals("jay")){
                iterator.remove();
            }
        }
```

**这里补充一点比较重要，但是容易被忽视掉的知识点：**

- java 中的 `length`属性是针对数组说的,比如说你声明了一个数组,想知道这个数组的长度则用到了 length 这个属性.
- java 中的 `length()` 方法是针对字符串说的,如果想看这个字符串的长度则用到 `length()` 这个方法.
- java 中的 `size()` 方法是针对泛型集合说的,如果想看这个泛型有多少个元素,就调用此方法来查看!

## 比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同

- `HashSet`、`LinkedHashSet` 和 `TreeSet` 都是 `Set` 接口的实现类，都能保证元素唯一，并且`都不是线程安全`的。
- `HashSet`、`LinkedHashSet` 和 `TreeSet` 的主要区别在于底层数据结构不同。`HashSet` 的底层数据结构是哈希表（基于 `HashMap` 实现）。`LinkedHashSet` 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。`TreeSet` 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。
- 底层数据结构不同又导致这三者的应用场景不同。`HashSet` 用于不需要保证元素插入和取出顺序的场景，`LinkedHashSet` 用于保证元素的插入和取出顺序满足 FIFO 的场景，`TreeSet` 用于支持对元素自定义排序规则的场景

## HashMap底层原理，解决Hash冲突办法有哪些？

HashMap 通过 key 的 `hashcode` 经过扰动函数处理过后得到 hash 值，然后通过 `(n - 1) & hash` 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。

所谓`扰动函数`指的就是 HashMap 的 `hash` 方法。使用 `hash` 方法也就是扰动函数是为了防止一些实现比较差的 `hashCode()` 方法 换句话说使`用扰动函数之后可以减少碰撞`。

```java
    static final int hash(Object key) {
      int h;
      // key.hashCode()：返回散列值也就是hashcode
      // ^ ：按位异或
      // >>>:无符号右移，忽略符号位，空位都以0补齐
      return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
  }
```

## HashMap的扩容机制原理

- HashMap使用`数组＋链表＋红黑树`（JDK1.8增加了红黑树部分）实现的；
- `链表长度大于8`(TREEIFY_THRESHOLD )时，会把`链表转换为红黑树`；
- `红黑树节点个数小于6`( UNTREETFY_THRESHOLD )时才`转化为链表`，防止频繁的转化。

## HashMap 多线程操作导致死循环问题

主要原因在于并发下的 `Rehash 会造成元素之间会形成一个循环链表`。不过，jdk 1.8 后解决了这个问题;

但是还是不建议在多线程下使用 HashMap,因为多线程下使用 HashMap 还是会存在其他问题比如数据丢失。并发环境下推荐使用 ConcurrentHashMap 。

## HashMap多种遍历方式

- 迭代器 EntrySet:` Iterator<Map.Entry<Integer, String>> iterator = map.entrySet().iterator();`
- 迭代器 KeySet;
- ForEach+EntrySet:`for (Map.Entry<Integer, String> entry : map.entrySet())`;
- **ForEach+KeySet**:自己用得多
- Lambda:`map.forEach((key, value) -> System.out.println(key); System.out.println(value);});`
- Streams API 单线程：`map.entrySet().stream().forEach((entry) -> {……});`

性能对比：

![图片](D:\算法Typora\picture\640.png)

**应该尽量使用 `entrySet` 来实现 Map 集合的遍历**。

## ConcurrentHashMap 和 Hashtable 的区别

- **实现线程安全的方式**（重要）：
  - 在 JDK1.7 的时候，`ConcurrentHashMap` 对整个桶数组进行了分割分段(`Segment`，分段锁)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。
  - 到了 JDK1.8 的时候，`ConcurrentHashMap` 已经摒弃了 `Segment` 的概念，而是直接用 `Node` 数组+链表+红黑树的数据结构来实现，并发控制使用 `synchronized` 和 `CAS` 来操作。（JDK1.6 以后 `synchronized` 锁做了很多优化） 整个看起来就像是优化过且线程安全的 `HashMap`，虽然在 JDK1.8 中还能看到 `Segment` 的数据结构，但是已经简化了属性，只是为了兼容旧版本；
  - **`Hashtable`(同一把锁)** :使用 `synchronized` 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。

## ConcurrentHashMap线程安全实现？

Java 8 几乎完全重写了 `ConcurrentHashMap`，代码量从原来 Java 7 中的 1000 多行，变成了现在的 6000 多行。

`ConcurrentHashMap` 取消了 `Segment` 分段锁，采用 `Node + CAS + synchronized` 来保证并发安全。数据结构跟 `HashMap` 1.8 的结构类似，数组+链表/红黑二叉树。Java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）。

Java 8 中，锁粒度更细，`synchronized` **只锁定当前链表或红黑二叉树的首节点**，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升。

## 为什么不用二叉查找树代替而选择红黑树？为什么不一直使用红黑树？

- 红黑树是为了解决二叉查找树的缺陷：二叉查找树在特殊情况下会变成一条线性结构,遍历查找会非常慢；

- 红黑树属于平衡二叉树，如果链表长度很短的话，根本不需要引入红黑树，引入反而会慢。

## 说说你对红黑树的见解？

- 每个节点非红即黑
- 根节点总是黑色的
- 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）
- 每个叶子节点都是黑色的空节点（NIL节点）
- 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度 ）

## HashMap 和 HashTable 的区别

- **线程是否安全：** `HashMap` 是非线程安全的，`Hashtable` 是线程安全的,因为 `Hashtable` 内部的方法基本都经过`synchronized` 修饰。（如果你要保证线程安全的话就使用 `ConcurrentHashMap` 吧！）；
- **效率：** 因为线程安全的问题，`HashMap` 要比 `Hashtable` 效率高一点。另外，`Hashtable` 基本被淘汰，不要在代码中使用它；
- **对 Null key 和 Null value 的支持：** `HashMap` 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；`Hashtable 不允许有 null 键和 null 值`，否则会抛出 `NullPointerException`。
- **初始容量大小和每次扩充容量大小的不同 ：** ① 创建时如果不指定容量初始值，`Hashtable` 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。`HashMap` 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 `Hashtable` 会直接使用你给定的大小，而 `HashMap` 会将其扩充为 2 的幂次方大小（`HashMap` 中的`tableSizeFor()`方法保证）。也就是说 `HashMap` 总是使用 2 的幂作为哈希表的大小。
- **底层数据结构：** JDK1.8 以后的 `HashMap` 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树，以减少搜索时间。`Hashtable` 没有这样的机制。

## 哪些集合类是线程安全的?哪些不安全?

- 线程安全的集合类:
  - Vector: 比ArrayList多了同步机制；
  - Hashtable；
  - ConcurrentHashMap:是一种高效并且线程安全的集合；
  - Stack:栈，也是线程安全的，继承于Vector；
- 线程不安全的集合类:
  - Hashmap
  - Arraylist
  - LinkedList
  - HashSet
  - TreeSet
  - TreeMap

## 说一说 PriorityQueue

`PriorityQueue` 是在 JDK1.5 中被引入的, 其与 `Queue` 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。

这里列举其相关的一些要点：

- `PriorityQueue` 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据
- `PriorityQueue` 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。
- `PriorityQueue` 是非线程安全的，且不支持存储 `NULL` 和 `non-comparable` 的对象。
- `PriorityQueue` 默认是小顶堆，但可以接收一个 `Comparator` 作为构造参数，从而来自定义元素优先级的先后。

典型例题包括`堆排序、求第K大的数、带权图的遍历`等

## fast-fail错误机制

- fast-fail是Java集合的一种错误机制。当`多个线程对同一个集合进行操作`时，就有可能会产生fast-fail事件。例如:`当线程a正通过iterator遍历集合时，另一个线程b修改了集合的内容，此时modCount(记录集合操作过程的修改次数）会加1`，不等于expectedModCount，那么线程a访问集合的时候，就会抛出`ConcurrentModificationException`，产生fast-fail事件。边遍历边修改集合也会产生fast-fail事件。
- 解决方法:
  - 使用`Colletions.synchronizedList`方法或在修改集合内容的地方加上synchronized。这样的话，增删集合内容的同步锁会阻塞遍历操作，影响性能。
  - `使用CopyOnWriteArrayList`来替换ArrayList。在对`CopyOnWriteArrayList`进行修改操作的时候，`会拷贝—个新的数组`，对新的数组进行操作，`操作完成后再把引用移到新的数组`。

## Collections 工具类

- 排序
- 查找,替换操作

### [#](https://javaguide.cn/java/collection/java-collection-questions-02.html#排序操作)排序操作

```java
void reverse(List list)//反转
void shuffle(List list)//随机排序
void sort(List list)//按自然排序的升序排序
void sort(List list, Comparator c)//定制排序，由Comparator控制排序逻辑
void swap(List list, int i , int j)//交换两个索引位置的元素
void rotate(List list, int distance)//旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面
```

### [#](https://javaguide.cn/java/collection/java-collection-questions-02.html#查找-替换操作)查找,替换操作

```java
int binarySearch(List list, Object key)//对List进行二分查找，返回索引，注意List必须是有序的
int max(Collection coll)//根据元素的自然顺序，返回最大的元素。 类比int min(Collection coll)
int max(Collection coll, Comparator c)//根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c)
void fill(List list, Object obj)//用指定的元素代替指定list中的所有元素
int frequency(Collection c, Object o)//统计元素出现次数
int indexOfSubList(List list, List target)//统计target在list中第一次出现的索引，找不到则返回-1，类比int lastIndexOfSubList(List source, list target)
boolean replaceAll(List list, Object oldVal, Object newVal)//用新元素替换旧元素
```



# JVM

## JVM内存结构

JVM内存结构分为5大区域，`程序计数器`、`虚拟机栈`、`本地方法栈`、`堆`、`方法区`。

![img](D:\算法Typora\picture\jvm内存结构0.png)

- `程序计数器`:当前线程所执行的字节码的`行号指示器`;
  - 字节码解释器通过改变程序计数器来依次读取指令，从而`实现代码的流程控制`，如：顺序执行、选择、循环、异常处理。
  - 在多线程的情况下，程序计数器用于`记录当前线程执行的位置`，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了;
  - ⚠️ 注意 ：程序计数器是唯一一个不会出现 `OutOfMemoryError` 的内存区域
- `虚拟机栈:`栈由一个个`栈帧`组成，而每个栈帧中都拥有：`局部变量表、操作数栈、动态链接、方法返回地址`。
  - **局部变量表** 主要存放了编译期可知的各种数据类型（`基本数据类型`）和`对象引用`（reference 类型）
  - **操作数栈** 主要作为方法调用的中转站使用，用于`存放方法执行过程中产生的中间计算结果`。
  - **动态链接** 主要服务一个方法需要调用其他方法的场景。
  - 程序运行中栈可能会出现两种错误：
    - **`StackOverFlowError`：** 若栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 `StackOverFlowError` 错误。
    - **`OutOfMemoryError`：** 如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出`OutOfMemoryError`异常。
- `本地方法栈:`**本地方法栈则为虚拟机使用到的 Native 方法服务。**
- `堆:`**此内存区域的唯一目的就是存放对象实例，`几乎所有的对象实例以及数组都在这里分配内存`。**
  - 从垃圾回收的角度：新生代和老年代；再细致一点有：Eden、Survivor、Old 等空间；
  - JDK 7 版本之前:新生代内存(Young Generation) 老生代(Old Generation) 永久代(Permanent Generation)
  - **JDK 8 版本之后 PermGen(永久) 已被 Metaspace(元空间) 取代，元空间使用的是直接内存**
- `方法区`:会存储已被虚拟机加载的 **类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据**。

📕：Java 世界中“几乎”所有的对象都在堆中分配，但是，随着 `JIT 编译器`的发展与`逃逸分析技术`逐渐成熟，`栈上分配、标量替换`优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。从 JDK 1.7 开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是`未逃逸出去`），那么对象`可以直接在栈上分配内存`。

## JVM内存结构中线程私有和线程共享的是哪些？

**线程`私有`的：**

- 程序计数器
- 虚拟机栈
- 本地方法栈

**线程`共享`的：**

- `堆`
- `方法区`
- `直接内存` (非运行时数据区的一部分)

## 说一下堆栈的区别?

1.`堆的物理地址分配是不连续`的，`性能较慢`;`栈的物理地址分配是连续`的，性能相对较快。

2.`堆存放的是对象的实例和数组`;栈存放的是局部变量，操作数栈，返回结果等。

3.堆是线程共享的;栈是线程私有的。

## 什么是类加载？类加载的过程？

类的加载指的是`将类的class文件中的二进制数据读入到内存`中，`将其放在运行时数据区的方法区`内,`然后在堆区创建一个此类的对象`，通过这个对象可以访问到方法区对应的类信息。

![img](D:\算法Typora\picture\类加载.png)

- `加载`
  - 1.通过`类的全限定名（包名 + 类型名）`获取定义此类的二进制字节流
  - 2.将字节流所代表的`静态存储结构转换为方法区的运行时数据结构`
  - 3.在内存中`生成一个代表该类的class对象`，作为方法区类信息的访问入口
- `验证`
  - 确保Class文件的`字节流`中包含的信息`符合虚拟机规范`，保证在运行后不会危害虚拟机自身的安全。主要包括四种验证:`文件格式验证，元数据验证，字节码验证，符号引用验证。`
- `准备`
  - 为`类变量分配内存`并设置类变量`初始值`的阶段。
- `解析`
  - 虚拟机`将常量池内的符号引用替换为直接引用`的过程。符号引用用于描述目标，直接引用直接指向目标的地址。
- `初始化`
  - 开始执行类中定义的Java代码，初始化阶段是`调用类构造器的过程`。

## 什么是双亲委派模型？为什么需要双亲委派？类加载器有哪些？

📕：一个类加载器`收到一个类的加载请求`时，它首先`不会自己尝试去加载它`，而是把这个请求`委派给父类加载器去完成`（`java.lang.ClassLoader`中的`loadClass()`），这样层层委派，因此所有的加载请求最终都会`传送到顶层的启动类加载器`中，只有当`父类加载器反馈自己无法完成这个加载请求时`，`子加载器才会尝试`自己去加载。

![img](D:\算法Typora\picture\双亲委派.png)

**双亲委派模型的好处**:

​	双亲委派模型保证了 Java 程序的稳定运行，可以`避免类的重复加载`（JVM `区分不同类`的方式`不仅仅根据类名`，`相同的类文件被不同的类加载器加载产生的是两个不同的类`），也`保证了 Java 的核心 API 不被篡改`。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 `java.lang.Object` 类的话，那么程序运行的时候，系统就会出现多个不同的 `Object` 类。

**类加载器**：`通过类的全限定名获取该类的二进制字节流`的代码块叫做类加载器

- `启动类加载器`:用来加载`Java核心类库`，无法被Java程序直接引用。
- `扩展类加载器`:它用来加载`Java的扩展库`。Java虚拟机的实现会提供一个扩展库目录。该类加载器在此目录里面查找并加载Java类。
- `系统类加载器`:它根据应用的类路径来加载Java类。可通过 `ClassLoader.getSystemClassLoader()`获取它。
- `自定义类加载器`:`通过继承 java.lang.ClassLoader类的方式实现`。

## Java字符串常量池里存的是String对象还是引用？

***\*结论：对象！\****

String类的intern()方法：一个初始为空的字符串池，它由类String独自维护。当调用 intern方法时，`如果池已经包含一个等于此String对象的字符串（用equals(oject)方法确定），则返回池中的\字符串\`。否则，将此String对象添加到池中，并返回此String对象的引用。



## JVM调优你用什么工具，具体怎么做的，怎么调优

# Java 并发

## 1、volatile关键字？

- 在`并发`的领域中，存在三大特性：`原子性，有序性，可见性`。
- volatile关键字`用来修饰对象的属性`，在并发环境下可以`保证这个属性的可见性`。
- 对于`加了volatile关键字的属性`，在这个属性`进行修改时`，会`直接将CPU高级缓存中的数据写回到主内存`，对这个变量的读取也会直接从主内存中读取，从而保证了可见性。
- `底层是通过操作系统的内存屏障来实现的`，由于使用了内存屏障，所以会`禁止指令重排`，所以也就同时`保证了有序性`，在很多并发场景下，如果用好volatile关键字可以很好的提高执行效率。

## 2、Synchronized关键字？

## 3、volatile和synchronized的区别

## 4、线程池？

## 3、TheadLocal的底层原理？

- `ThreadLocal`是Java中所提供的`线程本地存储机制`，可以利⽤该机制将数据缓存在某个线程内部，该线程可以在任意时刻、任意⽅法中获取缓存的数据
- ThreadLocal底层是`通过ThreadLocalMap来实现`的，**`每个Thread对象`**（注意不是ThreadLocal对象）中`都存在⼀个ThreadLocalMap`，Map的`key为ThreadLocal对象，Map的value为需要缓存的值`
- 如果在`线程池中使用ThreadLocal会造成内存泄漏`，因为当`ThreadLocal对象使用完之后`，应该要把设置的key，value，也就是`Entry对象进⾏回收`，
- 但`线程池中的线程不会回收`，而线程对象是通过强引⽤指向ThreadLocalMap`，`ThreadLocalMap也是通过强引用指向Entry对象;
  - **`线程不被回收->[线程对象强引用ThreadLocalMap]->[ThreadLocalMap强引用Entry对象]->Entry对象也就不会被回收->从⽽出现内存泄漏`**
- 解决办法是，在使用了ThreadLocal对象之后，`⼿动调⽤ThreadLocal的remove⽅法`，手动清楚Entry对象
- ThreadLocal经典的`应用场景就是连接管理`（⼀个线程持有⼀个连接，该连接对象可以在不同的⽅法之间进⾏传递，线程之间不共享同⼀个连接）
  



- volatile，线程池（其中的参数，）和ThreadLocal的说辞；

- 锁相关知识，synchronized+volatile(1.8版本)的用法；

- ThreadLocal里可能引发内存泄漏的问题；

- 因线程池等待队列设置不当而导致的OOM问题；

# 分布式组件



- 1 Redis，Dubbo，kafka等组件的超时问题，以及对应的OOM问题。
- 2 Netty堆外内存导致的OOM。
- 3 Netty半包粘包。Netty整合线程池，因线程池等待队列设置不当而导致的oom。
- 4 kafka重发和堆积消息过多的问题。

## spring中用到的设计模式?

- `工厂模式`：在各种`BeanFactory`以及`ApplicationContext`创建中都用到了；
- `模版模式`：在各种`BeanFactory`以及`ApplicationContext`实现中也都用到了；
- `代理模式`：在`AOP实现中用到了JDK和CJLIB的动态代理`；
- `单例模式`:这个比如在`创建bean的时候，处理循环依赖问题时候`。
- Tomcat中使用`外观模式`：因为Tomcat中有很多不同的组件，每个组件需要相互通
  信，但又不能将自己内部数据过多地暴露给其他组件。用外观模式隔离数据是个很好的方法。
- `策略模式`:在Java中的应用，`Comparator这个接口就是为策略模式`。比如说Collections里面有一个sort方法，因为集合里面的元素有可能是复合对象，复合对象并不像基本数据类型，可以根据大小排序，复合对象怎么排序呢？基于这个问题考虑，Java要求如果定义的复合对象要有排序的功能，就`自行实现Comparable接口或Comparator接口。`
- `原型模式`：`使用原型模式创建对象比直接new一个对象在性能上好得多`，因为Object类的clone()方法是一个native方法，它直接操作内存中的二进制流，特别是复制大对象时，性能的差别非常明显。
- `迭代器模式`：Iterable接口和Iterator接口 这两个都是迭代相关的接口，可以这么认为，实现了Iterable接口，则表示某个对象是可被迭代的；Iterator接口相当于是一个迭代器，实现了Iterator接口，等于具体定义了这个可被迭代的对象时如何进行迭代的。

# 计算机网络

**Q1：为什么建立连接的过程中要三次握手，而不是两次？**

A：三次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。如果只有两次握手，那么有可能有一方是没有做好建立连接的准备的。



**Q2：为什么断开连接的过程中要四次挥手，而不是三次？**

A：由于TCP是可以双向传输数据的，如果只有三次，客户端发送完数据请求断开连接，而服务端不一定也同样发送完数据，若同时回ACK和FIN给客户端，断开连接，可能造成数据的损坏；若先发送ACK，再等B的数据发送完了再发送FIN和ACK，就可以保证传输数据的完整性。

# 操作系统

# MySQL

## 1、索引一定时越多越好吗？

- 考虑到`索引的维护代价、空间占用和查询时回表的代价`，不能认为索引越多越好。索引一定是`按需创建`的，并且要尽可能确保足够轻量。 一旦创建了多字段的联合索引，我们要考虑`尽可能利用索引本身完成数据查询，减少回表`。

- 不能认为建了索引就一定有效，`对于后缀的匹配查询、查询中不包含联合索引的第一列、查询条件涉及函数计算等无法使用索引`。 即使SQL本身符合索引使用条件，MySQL也会通过评估各种查询方式的代价，来决定是否走索引，走哪个索引。

- 尝试通过索引进行SQL性能优化时，请一定`通过执行计划或实际的效果来确认索引是否能有效改善性能问题`，否则增加了索引不但没解决性能问题，还增加了数据库增删改的负担。 对`EXPLAIN`结果困惑的，还可以利用`optimizer_trace`查看详细的执行计划，各个索引的成本是多少，看看到底怎么挑选出来的最终方案。



# Redis

### 一、知识点

https://www.dabin-coder.cn/redis/redis-basic/1-introduce.html

#### 1、关系型数据库和非关系型数据库

- 传统关系型数据库是结构化数据，每一张表都有严格的约束信息：字段名.字段数据类型.字段约束等等信息，插入的数据必须遵守这些约束；

- NoSql则对数据库格式没有严格约束，往往形式松散，自由；可以是键值型，也可以是文档型。甚至可以是图格式；
- **关联和非关联**：传统数据库的表与表之间往往存在关联，例如外键；而**非关系型数据库不存在关联关系**，要维护关系要么靠代码中的业务逻辑，要么靠数据之间的耦合；
- **查询方式**：传统关系型数据库会基于Sql语句做查询，语法有统一标准；而不同的非关系数据库查询语法差异极大，五花八门各种各样。
- **事务**：传统关系型数据库能满足事务ACID的原则，而**非关系型数据库往往不支持事务**，或者**不能严格保证ACID**的特性，只能实现基本的一致性

![image-20220818163202995](D:\算法Typora\picture\image-20220818163202995.png)

#### 2、常见命令及基本数据类型

##### 一、常见命令与redisObject

- 通用指令：KEYS DEL EXISTS EXPIRE TTL

- Redis中的**任意数据类型的键和值都会被封装为一个RedisObject，也叫做Redis对象**


![image-20220819170140033](D:\算法Typora\picture\image-20220819170140033.png)

- Redis的key允许有多个单词形成层级结构，多个单词之间用':'隔开 -> `项目名：业务名：类型：id`

##### 二、基本数据类型

- **`String`**类型根据字符串的格式不同，又可以分为：string int float

  - 基本编码方式是**RAW**，基于**简单动态字符串（SDS）**实现，存储上限为512mb。

  - 如果存储的SDS长度**小于44字节，则会采用EMBSTR编码**，此时object head与SDS是一段连续空间。申请内存时只需要调用一次内存分配函数，效率更高。

  - 如果存储的字符串是整数值，并且大小在LONG_MAX范围内，则会采用**INT编码**

- **`Hash`**结构可以将对象中的每个字段独立存储，可以针对单个字段做CRUD；

  - 底层实现**压缩列表ziplist 或者 字典dict；**

- **`List`**类似LinkedList，可以看做是双向链表结构；**常用来存储一个有序数据**，例如：朋友圈点赞列表，评论列表；

  - 利用List模拟一个栈：

    - 入口和出口在同一边，即`LPUSH+LPOP`或者 `RPUSH+RPOP` 

    利用List模拟一个队列：

    - 入口入口在不同边，即`LPUSH+RPOP`或者 `RPUSH+LPOP` 

    利用List结构模拟一个阻塞队列（出队时阻塞出队）：

    - 入口入口在不同边，即`LPUSH+BRPOP`或者 `RPUSH+BLPOP` 

- **`Set`****可以看做是一个value为null的HashMap**。因为也是一个hash表，因此具备与HashSet类似的特征，可以求交并差；

  - SCARD key： 返回set中元素的个数
  - SISMEMBER key member：判断一个元素是否存在于set中
  - SMEMBERS：获取set中的所有元素

- **`SortedSet`**是一个可排序的set集合，与Java中的TreeSet有些类似，但底层数据结构却差别很大。SortedSet中的每一个元素都带有一个**score属性**，可以基于score属性对元素排序，**底层的实现是一个跳表（SkipList）加 hash表。**应用：排行榜

  - ZSCORE key member : 获取sorted set中的指定元素的score值
  - ZRANK key member：获取sorted set 中的指定元素的排名,默认从**0**开始
  - ZCOUNT key min max：统计score值在给定范围内的所有元素的个数
  - ZRANGE key min max：按照score排序后，获取指定排名范围内的元素
  - 🐖：所有的排名默认都是升序，如果要降序则在**命令的Z后面添加REV**即可
  - 使用ZSet实现延时队列：拿时间戳作为score,消息内容作为key,调用zadd来生产消息,消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理

#### 3、数据结构底层实现

| **数据类型** | **编码方式**                                       |
| ------------ | -------------------------------------------------- |
| OBJ_STRING   | int、embstr、raw（后两个都是基于SDS实现）          |
| OBJ_LIST     | LinkedList和ZipList(3.2以前)、QuickList（3.2以后） |
| OBJ_SET      | intset、HT                                         |
| OBJ_ZSET     | ZipList(3.2以前)、HT、SkipList                     |
| OBJ_HASH     | ZipList(3.2以前)、HT                               |

#### 4、Redis的java客户端

- Jedis：以Redis命令作为方法名称，学习成本低，简单实用。但是**Jedis实例是线程不安全的，多线程环境下并且频繁的创建和销毁连接会有性能损耗，需要基于连接池来代替Jedis的直连方式；**
  - 这里使用设计一个JedisConnectionFacotry：**工厂设计模式**是实际开发中非常常用的一种设计模式，我们可以使用工厂，去降低代码的耦合，比如Spring中的Bean的创建，就用到了工厂设计模式；

- lettuce：Lettuce是基于Netty实现的，**支持同步、异步和响应式编程方式，并且是线程安全**的。支持Redis的哨兵模式、集群模式和管道模式。
- Redisson：是**在Redis基础上实现了分布式的可伸缩的java数据结构，例如Map、Queue等**，而且支持跨进程的同步机制：Lock、Semaphore等，比较适合用来实现特殊的功能需求。
- SpringDataRedis：提供了对不同Redis客户端的整合（Lettuce和Jedis）；



### 二、面试题

#### ❗Q:Redis热点数据问题，怎么发现热点数据，怎么优化解决？

​	短时间内某些 key 访问量过于大，对于这种相同的 key 会请求到同一台数据分片上，**导致该分片负载较高**成为瓶颈问题，导致雪崩等一系列问题。

- 热点数据最大的问题是会造成集群**负载不均衡**（❗**数据倾斜❗**）导致的故障；
- **`热点 Key + 大 Value` 同时存在**，服务器杀手。
  - 数据倾斜问题：大 Value 会导致集群不同节点数据分布不均匀，造成数据倾斜问题，大量读写比例非常高的请求都会落到同一个 redis server 上，该 redis 的负载就会严重升高，容易打挂。
  - QPS 倾斜：分片上的 QPS 不均。
  - 大 Value 会导致 Redis 服务器缓冲区不足，造成 get 超时->**数据倾斜**。
  - 由于 Value 过大，导致服务器IO阻塞。
  - Redis 缓存失效导致数据库层被击穿的连锁反应。
- **怎么发现**：
  - **提前获知法**；
  - **Redis 客户端收集法**：无法预知 key 的个数；
  - **Redis 集群代理层统计**：在 Proxy 层做收集上报；缺点：并非所有的 Redis 集群架构都有 proxy；
  - **Redis 服务端收集**：监控 Redis 单个分片的 QPS，发现 QPS 倾斜到一定程度的节点执行 monitor命令（统计出一段时间某个节点的所有命令），分析获取热点 key；
    - 缺点： 影响内存和性能，只能统计单个节点，集群时需要汇总
  - **修改 Redis 源代码**：4.0：尝试基于 LFU 的热点 key 发现机制？

- **优化解决：**数据分片，让压力均摊到集群的多个分片上；第二是迁移隔离。
  - **key 拆分**：热点 key 可以拆分为若干个新的 key 分布到不同 Redis 节点上，从而减轻压力
  - **迁移热点 key**：将热点 key 所在的 slot 单独**迁移到一个新的 Redis 节点**上->不影响其他业务
  - **热点 key 限流：**对于写命令我们可以通过单独针对这个热点 key 来限流
  - **增加本地缓存**：将热点 key 缓存到业务机器的本地缓存中->缺点：数据不一致

#### ❗Q:秒杀项目最关键的点是什么？

- **`限流`**：由于活动库存量一般都是很少，对应的只有少部分用户才能秒杀成功。所以我们需要限制大部分用户流量，**只准少量用户流量进入后端服务器。**
- **`削峰`**：在开始时候会有一个瞬间流量峰值。实现流量削峰填谷，一般的**采用缓存和 MQ 中间件**来解 决。
- **`异步`**：当做高并发系统来处理，设计成**异步处理的任务**，提高网站的整体可用性。
- **`缓存`**：秒杀系统的瓶颈主要体现在**下订单、扣减库存**流程中->把部分业务逻辑迁移到Redis中

#### ❗Q:高性能、高可用、高并发？

> 高并发：我们使用 QPS来衡量**系统承载能力**，大于 10万；`负载均衡+池化技术(连接复用)+流量漏斗+拦截器分发`

> 高性能：要求**请求延迟**小于 100 ms；`多级缓存 + 日志优化（先写到内存），避免IO-wait`

> 高可用：可用性**高于 99.99%；`可用时长+故障恢复耗时+服务等级协议：MTBF/(MTBF+MTTR)`
>
> - 主备切换，缩减故障时间
> - 熔断，提供过载保护
> - 限流，提供过载保护
> - 降级, 非核心的功能进行降级



#### Q1：Redis是什么？有什么优缺点？

- Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此**读写速度非常快**，常用于**缓存，消息队列、分布式锁等场景**。


- Redis 提供了多种数据类型来支持不同的业务场景，比如 `String`(字符串)、`Hash`(哈希)、 `List` (列表)、`Set`(集合)、`Zset`(有序集合)、`Bitmaps`（位图）、`HyperLogLog`（基数统计）、`GEO`（地理信息）、`Stream`（流），并且对数据类型的操作都是**原子性**的，因为执行命令由单线程负责的，不存在并发竞争的问题。

- 除此之外，Redis 还支持**`事务` 、`持久化`、`Lua 脚本`、`多种集群方案`（主从复制模式、哨兵模式、切片机群模式）、`发布/订阅模式`，`内存淘汰机制`、`过期删除机制`**等

#### Q2：Redis 和 Memcached 有什么区别？

- Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 **Memcached 只支持最简单的 key-value** 数据类型；
- Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 **Memcached 没有持久化功能**，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；
- Redis 原生支持集群模式，Memcached **没有原生的集群模式**，需要依靠客户端来实现往集群中分片写入数据；
- Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持

#### Q3:Redis 数据类型以及使用场景分别是什么？

 Redis 五种数据类型的应用场景：

- String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。**(SDS)**
- List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。**(3.2之前是双向链表或压缩列表；3.2后quickList)**
- Hash 类型：缓存对象、购物车等。(**压缩列表或哈希表** 7.0后压缩列表废弃->**listpack**)
- Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。**(HT+Intset)**
- Zset 类型：排序场景，比如排行榜、电话和姓名排序等。

Redis 后续版本又支持四种数据类型，它们的应用场景如下：

- BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
- HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；
- GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
- Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。

#### Q4:Redis是单线程吗，说一说其单线程模型？

​	**Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的**，这也是我们常说 Redis 是单线程的原因；但Redis启动时会有后台线程，单独开启线程去处理耗时任务长的处理：比如处理关闭文件、AOF 刷盘、异步释放 Redis 内存（unlink 命令来异步删除大key）；

​	当我们的客户端想要去**连接我们服务器**，会去先到**IO多路复用模型去进行排队**，会有一个**连接应答处理器**，他会去接受读请求，然后又把读请求注册到具体模型中去，此时这些建立起来的连接，如果是客户端请求处理器去进行执行命令时，他会去把数据读取出来，然后把数据放入到client中， clinet去解析当前的命令转化为redis认识的命令，接下来就开始处理这些命令，从redis中的command中找到这些命令，然后就真正的去操作对应的数据了，当数据操作完成后，会去找到命令回复处理器，再由他将数据写出。

#### Q5:为什么采用了单线程模型还这么快？

- Redis 的大部分操作**都在内存中完成**，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；
- Redis 采用单线程模型可以**避免了多线程之间的竞争**，省去了**多线程切换**带来的时间和性能上的开销，而且也**不会导致死锁**问题。
- Redis 采用了 **I/O 多路复用机制**处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

#### Q6:Redis 6.0 之后为什么引入了多线程？

- 在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，**Redis 的性能瓶颈有时会出现在网络 I/O 的处理上**。
- 但是**对于命令的执行，Redis 仍然使用单线程来处理**；

#### Q7:Redis如何实现持久化？

Redis 共有三种数据持久化的方式：

- **AOF 日志**：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里，可以看做是命令日志文件；
  - Redis 提供了 3 种缓冲区刷回硬盘的策略：**Always**、**Everysec**、**No**（操作系统）
  - AOF过大（percentage100+min_size=64mb）触发**AOF 重写机制**->**由后台子进程 \*bgrewriteaof\* 来完成的**;为了解决数据不一致问题，Redis 设置了一个 **AOF 重写缓冲区**，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。
  - 优点：数据丢失少，每秒刷盘的话最多丢失1秒的数据；没有磁盘寻址的开销，写入性能高；
  - 缺点：同一份文件AOF比RDB更大；**不适合写多读少的场景**；**数据恢复慢**；

- **RDB 快照**：将某一时刻的内存数据，以特定二进制的方式写入磁盘（copy-on-write）；手动触发（sava/bgsave）
  - 优点：恢复数据块
  - 缺点：bgsave是创建子进程进行fork，属于重量级操作；新老版本的RDB存在兼容性问题

![image-20220819224724436](D:\算法Typora\picture\image-20220819224724436.png)

- **混合持久化方式**：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点;AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。

#### Q8：Redis有哪些部署方案?

- **单机版**:单机部署，单机redis能够承载的QPS大概就在上万到几万不等。这种部署方式很少使用。
  - 存在的问题:1、内存容量有限2、处理能力有限3、无法高可用。
- **主从模式**:一主多从，主负责写，并且将数据复制到其它的slave节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，**支撑读高并发**。master节点挂掉后，需要**手动指定新的master**，可用性不高，基本不用。
- **哨兵模式**:**主从复制存在不能自动故障转移、达不到高可用**的问题。哨兵模式解决了这些问题。通过哨兵机制可以自动切换主从节点。master节点挂掉后，哨兵进程会主动选举新的 master，可用性高，但是每个节点存储的数据是一样的，浪费内存空间。数据量不是很多，集群规模不是很大，需要自动容错容灾的时候使用。
- **Redis cluster**:服务端分片技术，3.0版本开始正式提供。Redis Cluster并没有使用一致性hash，而是采用slot(槽)的概念，一共分成16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确的节点上执行。主要是**针对海量数据+高并发+高可用**的场景，如果是海量数据，如果你的数据量很大，那么建议就用Redis cluster，所有主节点的容量总和就是Redis cluster可缓存的数据容量。

#### Q9:Redis如何实现服务高可用，谈谈主从架构？

​	要从 Redis 的主从复制、哨兵模式、切片集群说起。

- 主从复制：**读写分离**、replicaof、**主从一致**、长连接、异步复制
  - 主从复制模式：全量复制（初次复制）+增量复制（从节点宕机重启后，主节点根据offset补发丢失的数据）
  - 同步机制：
    - 1.保存主节点信息。
    - 2.主从建立socket连接。
    - 3.从节点发送ping命令进行首次通信，主要用于检测网络状态。
    - 4.权限认证。
    - 5.同步数据集。第一次同步的时候，**从数据库启动后会向主数据库发送SYNC命令**。主数据库接**收到命令后**开始在后台保存快照(**RDB持久化过程**)，并将保存快照过程接收到的**命令缓存**起来。当快照完成后，Redis会将快照文件和缓存的命令发送到从数据库。从数据库接收到后，会载入快照文件并执行缓存的命令。以上过程称为复制初始化。
    - 6.复制初始化完成后，主数据库每次收到写命令就会将命令同步给从数据库，从而实现主从数据库数据的一致性。
- **从数据库持久化**：因为持久化操作比较耗时，所以可以放到从数据库来做。
- **主从架构时过期KEY**：主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条**del命令**发送给从节点，**从节点收到该命令后，就进行删除key的操作**。
- replication buffer（全量复制时） 、repl backlog buffer（增量复制时、**环状、覆盖数据**）
- 主从切换如何减少丢失：
  - 第一种：客户端暂时将数据写入本地缓存；
  - 第二种：客户端将数据写入消息队列，发送一个**延时消费消息**，比如10分钟后在消费消息队列中的数据，然后再写到主节点。

#### Q10:哨兵机制及其工作原理？

- 哨兵作用：作用：主从故障转移；哨兵节点主要负责三件事情：**监控、选主、通知**

  - 监控：PING-PONG、针对「主节点」设计「**主观下线**」和「**客观下线**」、最少三个哨兵
  - 选主：
    - 将主节点判定为客观下线的哨兵通过投票先成为**候选者**；候选者向其他哨兵**发起命令表示希望成为Leader**；再次进行投票！
    - 哨兵Leader选新主节点：先过滤掉已下线的从节点；对所有从节点进行三轮考察：**优先级高、复制进度靠前、ID 号小**
    - 选出后给被选中从节点发送`SLAVEOF no one`

  - 通知：新主节点的信息**通过 Redis 的发布者/订阅者机制**通知给客户端；同时哨兵又**通过 INFO 命**令，在主节点里获得了**所有从节点**连接信息，于是就能和从节点建立连接，并进行监控了。
  - **哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的**

#### Q11:分片集群的优缺点？

优点:

- 无中心架构，支持**动态扩容**;
- 数据按照slot存储分布在多个节点，**节点间数据共享**，**可动态调整数据分布**;
- **高可用性**。部分节点不可用时，集群仍可用。**集群模式能够实现自动故障转移(failover)**，节点之间通过**gossip协议**交换状态信息，用投票机制完成 slave 到 Master的角色转换。

缺点:

- 不支持批量操作(pipeline) 。
- 数据通过异步复制，不保证数据的强一致性。
- 事务操作支持有限，只支持多key 在同一节点上的事务操作，当多个 key分布于不同的节点上时无法使用事务功能。
- key作为数据分区的最小粒度，不能将一个很大的键值对象如hash 、 list等映射到不同的节点。。不支持多数据库空间，单机下的Redis可以支持到16个数据库，集群模式下只能使用1个数据库空间。
- 只能使用0号数据库。

#### Q12:Redis哪个数据类型用跳表

- Redis 只有 Zset 对象的底层实现用到了跳表;

#### Q13:跳表查找，插入，删除时间复杂度

- 跳表的查找、插入、删除的时间复杂度都是 O(logn)，而且可以按照范围区间查找元素

#### Q14:Redis中zset怎么做的

- zset 结构体里有两个数据结构：一个是跳表，一个是哈希表。这样的好处是既能进行高效的**范围查询**，也能进行高效**单点查询。**
- Zset 对象在执行数据插入或是数据更新的过程中，会依次**在跳表和哈希表中插入或更新相应的数据**，从而**保证了跳表和哈希表中记录的信息一致。**
- 

#### Q15:Redis中的过期删除策略？

Redis 使用的过期删除策略是「惰性删除+定期删除」，删除的对象是已过期的 key。

![img](D:\算法Typora\picture\过期删除策略.jpg)

#### Q16:有哪些内存淘汰策略？

​	内存淘汰策略是解决内存过大的问题，当 Redis 的运行内存超过最大运行内存时，就会触发内存淘汰策略，Redis 4.0 之后共实现了 8 种内存淘汰策略：

![img](D:\算法Typora\picture\内存淘汰策略.jpg)

#### Q17:什么是缓存雪崩、击穿、穿透？如何解决？

- **缓存雪崩**：同一时间缓存中大量的key失效或者Redis宕机，导致大量用户请求直接访问数据库；
  - 大量数据同时过期：
    - **均匀设置过期时间**：应该避免将大量的数据设置成同一个过期时间，给这些数据的过期时间加上一个随机数；
    - **互斥锁**：如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存，锁也要加过期时间；
    - **双 key 策略**：一个是**主 key，会设置过期时间**，一个是**备 key，不会设置过期**，它们只是 key 不一样，但是 value 值是一样的，相当于给缓存数据做了个副本。
    - **缓存预热**：提前把数据缓起来，而不是等待用户访问才来触发缓存构建
  - Redis故障宕机：
    - **服务熔断**或请求限流机制：暂停业务应用对缓存服务的访问，直接返回错误
    - 构建 Redis 缓存高可靠**集群**：利用哨兵故障转移。
- **缓存击穿**：如果缓存中的**某个热点数据过期**了，此时大量的请求访问了该热点数据；数据库很容易就被高并发的请求冲垮；
  - 热点数据永不过期
  - 互斥锁方案
- **缓存穿透**：**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失；
  - 非法请求的限制：在API入口处我们要判断求**请求参数是否合理**，请求参数**是否含有非法值**、请求**字段是否存在**；
  - **缓存空值**或者默认值：
  - 使用**布隆过滤器**：**快速判断数据是否存在**，避免通过查询数据库来判断数据是否存在；
    - 由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成;
    - 使用 N 个哈希函数分别对数据做哈希计算，得到 **N 个哈希值**；
    - 将第一步得到的 N 个哈希值对位图数组的长度**取模**，**得到每个哈希值在位图数组的对应位置**。
    - 将每个哈希值在位图数组的对应位置的值**设置为 1**；
    - 当有数据来时，计算N次hash后判断N个位置上是否都为1->数据存在
    - **存在哈希冲突的可能性**：查询到数据不存在，数据库中一定就不存在这个数据。

#### Q18:Redis 是如何实现LRU算法的？LRU和LFU有什么优缺点，应用场景

- LRU:**最近最少使用**，会选择淘汰最近最少使用的数据。
  - Redis 实现的是一种**近似 LRU 算法**，目的是为了更好的节约内存，它的**实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间**。
  - 当 Redis 进行内存淘汰时，会使用**随机采样的方式来淘汰数据**，它是随机取 5 个值（此值可配置），然后**淘汰最久没有使用的那个**。
  - 优点：
    - 相较于传统使用链表实现的LRU不用为所有的数据维护一个大链表，节省了空间占用；
    - 不用在每次数据访问时都移动链表项，提升了缓存的性能；
  - 缺点：
    - **无法解决缓存污染问题**，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。
- LFU：**最近最不常用的**
  - LFU 算法相比于 LRU 算法的实现，多记录了「**数据的访问频次**」的信息
- 区别：
  - **在 LRU 算法中**，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。
  - **在 LFU 算法中**，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，**高 16bit 存储 ldt**(Last Decrement Time)，**低 8bit 存储 logc**(Logistic Counter)-> **logc 会随时间推移而衰减的**。

#### Q19:为什么Redis选择跳表而不是红黑树来实现有序集合

Redis 中的有序集合(zset) 支持的操作：

- 插入一个元素
- 删除一个元素
- 查找一个元素
- 有序输出所有元素
- 按照范围区间查找元素（比如查找值在 [100, 356] 之间的数据）

​	其中，**前四个操作红黑树也可以完成**，**且时间复杂度跟跳表是一样的**。但是，**按照区间来查找数据这个操作，红黑树的效率没有跳表高**。按照区间查找数据时，跳表可以做到 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了，非常高效。

#### **Q20：为什么Redis执行Lua脚本能够保证原子性？**使用Lua脚本的优势?

- Redis在执行Lua脚本时，是**单线程执行**lua脚本，不会执行其他脚本或Redis命令，类似开启事务，触发事务；

- 从所有其他客户端的角度来看，脚本的效果要么仍然不可见，要么已经完成。
- 在 Redis 服务器执行EVAL命令时，其它客户端发送的命令将被阻塞，直到EVAL命令执行完毕为止。
- 因此 LUA 脚本不宜编写一些过于复杂了逻辑，必须尽量保证 Lua 脚本的效率，否则会影响其它客户端；
- 且一定要保证脚本的正确性，如果一个命令报错不会回滚已执行的命令。

**优势：**

- **支持原子性操作** - Redis会将整个脚本作为一个整体执行，中间不会被其他请求插入。因此在脚本运行过程中无需担心会出现竞态条件，无需使用事务
- **降低网络开销** - 将多个请求通过脚本的形式一次发送到服务器，减少了网络的时延
- **脚本复用**    - 客户端发送的脚本可支持永久存在redis中，这样其他客户端可以复用这一脚本，而不需要使用代码完成相同的逻辑。

#### Q21：常见的缓存更新策略？

- Cache Aside（旁路缓存）策略；Redis 和 MySQL都使用这种
  - **应用程序**直接与「数据库、缓存」交互，并**负责对缓存的维护**，该策略又可以细分为「读策略」和「写策略」
- Read/Write Through（读穿 / 写穿）策略；
  - 应用程序**只和缓存交互**，不再和数据库交互，而是由缓存和数据库交互，相当于**更新数据库的操作由缓存自己代理**。
- Write Back（写回）策略；
  - 在更新数据的时候，**只更新缓存**，同时将缓存数据设置为**脏**的，然后立马返回，并不会更新数据库。
  - 对于数据库的更新，会通过**批量异步更新**的方式进行。

#### Q22：缓存与数据库一致性？

- 更新 ＋ 更新（**由于并发都会导致缓存与数据库不一致**）请求 A 」和「请求 B 」两个请求，同时更新「同一条」数据
  - 先更新数据库，再更新缓存：数 1 -> 数 2 -> 缓 2 -> 缓1
  - 先更新缓存，再更新数据库：缓 1 -> 缓 2 -> 数 2 -> 数1 

- 更新 + 删除（考虑**「读 + 写」并发的时候**的时候）:**请求A**：删除缓存+更新数据库 `请求B`：查询缓存
  - 先删除缓存，再更新数据库：
    - **请求A**：删除缓存+更新数据库 `请求B`：查询缓存
    - **删缓存**-> `缓存未命中 -> 查数据库原始20 -> 原20更新至缓存` -> **数据库更新为21**
    - 问题：缓存为20，数据库为21 -> 解决办法是「**延迟双删**」
  - 先更新数据库，再删除缓存：
    - **请求A**：查询缓存 `请求B`：更新数据库+删除缓存
    - **缓存未命中 -> 查数据库原始20**  -> `数据库更新为21 -> 删缓存` -> **原20更新至缓存**
    - 问题：缓存为20，数据库为21 -> 但这种情况出现**概率极低，因为缓存的写入往往远快于数据库的写入**；

#### Q23:如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功？

- 问题：如果删除操作失败，会导致读到的是旧值
- 解决
  - 重试机制：引入**消息队列**，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。
    - 如果应用**删除缓存失败**，可以**从消息队列中重新读取数据**，然后再次删除缓存，这个就是**重试机制**。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。
    - 如果**删除缓存成功**，就要把数据**从消息队列中移除**，避免重复操作，否则就继续重试。
  - 订阅 MySQL binlog，再操作缓存：
    - 更新数据库成功，就会产生一条变更日志，记录在 binlog 里；
    - 通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除

#### ❗Q24:Redis是如何实现分布式锁？

​	利用Redis 本身**可以被多个客户端共享访问**，正好就是一个共享存储系统，可以**用来保存分布式锁**，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。

关键步骤：

- 加锁->`SET lock_key unique_value NX PX 10000` 
  - 原子性完成**读取锁变量**、**检查锁变量值**和**设置锁变量值**三个操作；
  - 锁变量需要**设置过期时间**，避免发生异常导致锁无法释放；
  - 锁变量的值需要能**区分来自不同客户端的加锁操作**，以免出现误释放，`unique_value`->客户端生成的唯一的标识；

- 解锁->将 lock_key 键删除（del lock_key）
  - 先判断执行操作的客户端就是加锁的客户端；
  - 释放锁
  - 所以解锁是有两个操作，这时就**需要 Lua 脚本来保证解锁的原子性**；

#### Q25:基于 Redis 实现分布式锁有什么优缺点？

- 优点
  - 性能高效 + 实现方便 + 避免单点故障
- 缺点：
  - 超时时间不好设置（基于**续约**改进） +  主从复制模式中的数据是**异步复制**的，这样导致**分布式锁的不可靠性**

#### Q26:Redis 如何解决集群情况下分布式锁的可靠性？

- 使用Redis 官方已经设计的一个分布式锁算法 **Redlock（红锁）**

- Redlock 算法的基本思路，**是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败**。
- 加锁过程：
  - 客户端获取当前时间（t1）
  - 按顺序依次向 N 个 Redis 节点执行加锁操作，注意这里是**给加锁这个操作本身设置超时时间**
  - 一旦客户端从超过半数（大于等于 N/2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2）
  - 计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 < 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。

Q27:主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？

- replication buffer 是在全量复制阶段会出现，**主库会给每个新连接的从库，分配一个** replication buffer；repl backlog buffer 是在增量复制阶段出现，**一个主库只分配一个**repl backlog buffer；
- 这两个 Buffer 都有大小限制的，当缓冲区满了之后。repl backlog buffer，因为是环形结构，会直接**覆盖起始位置数据**，replication buffer则会导致连接断开，删除缓存，从库重新连接，**重新开始全量复制**。

# 项目



![image-20220809205324664](D:\算法Typora\picture\image-20220809205324664.png)

## 项目总概



## 短信登录

通过 Redis 实现**共享 session**的短信登录功能，并使用**双拦截器**改进登录流程

这一块使用redis**共享session**来实现

**发送验证码：**

用户在提交手机号后，会校验手机号是否合法，如果不合法，则要求用户重新输入手机号

如果手机号合法，后台此时生成对应的验证码，同时将验证码保存至Redis，然后再通过短信的方式将验证码发送给用户

**短信验证码登录、注册：**

用户将验证码和手机号进行输入，后台从session中拿到当前验证码，然后和用户输入的验证码进行校验，如果不一致，则无法通过校验，如果一致，则后台根据手机号查询用户，如果用户不存在，则为用户创建账号信息，保存到数据库，无论是否存在，都会将用户信息保存到session中，方便后续获得当前登录信息

**校验登录状态:**

用户在请求时候，会**从cookie中携带着JsessionId到后台**，后台通过JsessionId从session中拿到用户信息，如果没有session信息，则进行拦截，如果有session信息，则**`将用户信息保存到threadLocal`**中，并且放行；

📕：在threadLocal中，无论是他的put方法和他的get方法， 都是先从获得当前用户的线程，然后从线程中取出线程的成员变量map，只要线程不一样，map就不一样，所以可以通过这种方式来做到**线程隔离**

### 1、用到的方法和工具：

- 生成验证码时用的是`hutool`工具包：`RandomUtil.randomNumbers(6)`;
- 注入Redis时使用的是`StringRedisTemplate`；
- 发送验证码 由于需要借助第三方服务器，暂时用log代替:`log.debug("发送短信验证码成功，验证码：{}",code);`这里使用的Log仓库是**Slf4j**

​	PS❓:为什么使用Slf4j:**slf4j就是各种接口的集合**，对外暴露相同的接口，用户可以使用自己指定的日志系统。一句话总结，**slf4j让你的代码独立于任何特定的日志系统API。**这样的特性，尤其适合于公共的库的开发

- 将User对象转为Hash存储至Redis时，借助hutool中的BeanUtil来转换；
- 拦截器是实现了spring中`web.servlet.HandlerInterceptor`，重写了前置拦截和销毁拦截（销毁即移除用户的ThreadLocal，避免内存泄漏）；让拦截器生效是在Config中实现一个`MvcConfig implements WebMvcConfigurer`（@Configuration），并重写其`addInterceptors`方法；
- 返回用户信息给浏览器时需隐藏用户的敏感信息，新建一个UserDTO对象->只有id、nickName、icon
- 根据手机号查询用户：`query().eq("phone", phone).one();`利用MybatisPlus提供的便捷查询

### 2、Session共享问题：

​	问题：每个tomcat中都有一份属于自己的session,假设用户第一次访问第一台tomcat，并且把自己的信息存放到第一台服务器的session中，但是第二次这个用户访问到了第二台tomcat，那么在第二台服务器上，肯定没有第一台服务器存放的session，所以此时 整个登录拦截功能就会出现问题；早期的方案是session拷贝；

​	解决：利用Redis的特性：`数据共享、内存存储、key-value结构`

- 首先考虑使用哪种数据结构？
  - 如果使用String，多占用一点空间；
  - 如果`使用哈希`，则他的value中只会存储他数据本身，且每个字段独立存储，方便CRUD；
- 对于key的设计：为了保护隐私，在后台生成一个随机串token，然后让前端带来这个token
- 基于Redis实现共享Session流程如下：

![image-20220809214116868](D:\算法Typora\picture\image-20220809214116868.png)

### 3、解决状态登录刷新问题

​	问题：单个拦截器只是拦截需要被拦截的路径，**`假设当前用户访问了一些不需要拦截的路径`**，那么这个拦截器就不会生效，所以此时**`令牌刷新的动作实际上就不会执行`**，所以这个方案是存在问题的；

​	优化方案：再添加一个拦截器，**`第一个拦截器中拦截所有的路径`**，把第二个拦截器做的事情放入到第一个拦截器中，同时刷新令牌，因为第一个拦截器有了threadLocal的数据，所以此时**`第二个拦截器只需要判断拦截器中的user对象是否存在即可`**，完成整体刷新功能。

> 第一个拦截器：重要的是将通过token查询到的Redis中存在用户保存到ThreadLocal中，并不真正拦截，用户存在时刷新其token；
>
> 第二个拦截器：查询ThreadLocal，用户不存在则拦截！

![image-20220823225824437](D:\算法Typora\picture\image-20220823225824437.png)

## 商户查询缓存

 实现商户**查询缓存**，实现模拟并解决**缓存穿透、缓存雪崩、缓存击穿**  

### 1、实现商铺和缓存与数据库双写一致

>根据id查询店铺时，如果缓存未命中，则查询数据库，将数据库结果写入缓存，并`设置超时时间`
>
>`根据id修改店铺时，先更新数据库，再删除缓存`

```java
    @Override
    @Transactional//加事务
    public Result update(Shop shop) {
        Long id = shop.getId();
        if (id == null) {
            return Result.fail("店铺id不能为空");
        }
        //为了减少线程安全问题，采用先更新数据库，再删除缓存的策略
        updateById(shop);
        stringRedisTemplate.delete(CACHE_SHOP_KEY + shop.getId());
        return Result.ok();
    }
```

### 2、缓存穿透问题的解决思路

> * 缓存空对象
>   * 优点：实现简单，维护方便
>   * 缺点：
>     * 额外的内存消耗
>     * 可能造成短期的不一致
> * 布隆过滤
>   * 优点：内存占用较少，没有多余key
>   * 缺点：
>     * 实现复杂
>     * 存在误判可能

`代码实现布隆过滤器：`

```Java
	/**
     * 一个长度为10亿的比特位
     */
    private static final int DEFAULT_SIZE = 256 << 22;
 
    private static final int[] seeds = {3, 5, 7, 11, 13, 31, 37, 61};
 
    private static HashFunction[] functions = new HashFunction[seeds.length];
 
    private static BitSet bitset = new BitSet(DEFAULT_SIZE);
 
    static {
        for (int i = 0; i < functions.length; i++) {
            functions[i]=new HashFunction(DEFAULT_SIZE,seeds[i]);
        }
    }
    static class HashFunction{
 
        private int size;
        private int seed;
 
        public HashFunction(int size, int seed) {
            this.size = size;
            this.seed = seed;
        }
 
        public int hash(String value){
            int result=0;
            int len=value.length();
            for (int i = 0; i < len; i++) {
                result=seed*result+value.charAt(i);
            }
            return (size-1)&result;
 
     		}
    }
    public static void add(String value) {
        if (value != null) {
            for (HashFunction f : functions) {
                //计算 hash 值并修改 bitmap 中相应位置为 true
                bitset.set(f.hash(value), true);
            }
        }
    }
 
    public static boolean contains(String value){
        if(value==null){
            return false;
        }
        boolean ret=true;
 
        for (HashFunction f : functions) {
            ret=bitset.get(f.hash(value));
            if(!ret){
                break;
            }
        }
        return ret;
    }
```

### 3、缓存雪崩问题及解决思路

> * `给不同的Key的TTL添加随机值`
> * 利用Redis`集群`提高服务的可用性
> * 给缓存业务添加`降级限流`策略
> * 给业务添加`多级缓存`

### 4、缓存击穿问题及解决思路

> * `互斥锁`:tryLock方法 + double check来解决；
> * `逻辑过期`:如果没有过期，则直接返回redis中的数据，如果过期，则`开启独立线程`后直接`返回之前的数据`，`独立线程去重构数据`，重构完成后释放互斥锁。

`利用互斥锁解决缓存击穿问题`：

进行查询之后，如果从缓存`没有查询到数据`，则`进行互斥锁的获`取，获取互斥锁后，判断是否获得到了锁，如果`没有获得到，则休眠`，过一会再进行尝试，直到获取到锁为止，才能进行查询；

`步骤：`

- 加锁（setIfAbsent）：利用redis的setnx方法来表示获取锁；
- 放锁（delete(key)）: 删除对应的key；

```java
private boolean tryLock(String key) {
    Boolean flag = stringRedisTemplate.opsForValue().setIfAbsent(key, "1", 10, TimeUnit.SECONDS);
    return BooleanUtil.isTrue(flag);//不直接返回flag是因为自动拆箱的时候可能出现空指针
}

private void unLock(String key) {
    stringRedisTemplate.delete(key);
}
```

`利用逻辑过期解决缓存击穿问题`

- 给原来redis中存储的数据的value需要带上过期时间；
- 新建一个RedisData实体类；

```java
private static final ExecutorService CACHE_REBUILD_EXECUTOR = Executors.newFixedThreadPool(10);
public Shop queryWithLogicalExpire( Long id ) {
	//… 省略查询判断等过程 …
    // 5.2.已过期，需要缓存重建
    // 6.缓存重建
    // 6.1.获取互斥锁
    String lockKey = LOCK_SHOP_KEY + id;
    boolean isLock = tryLock(lockKey);
    // 6.2.判断是否获取锁成功
    if (isLock){
        CACHE_REBUILD_EXECUTOR.submit( ()->{

            try{
                //重建缓存
                this.saveShop2Redis(id,20L);
            }catch (Exception e){
                throw new RuntimeException(e);
            }finally {
                unlock(lockKey);
            }
        });
    }
    // 6.4.返回过期的商铺信息
    return shop;
}
```



## 优惠卷秒杀

利用**Redis计数器**、 **Lua脚本**、 Redisson**分布式锁**和Stream**消息队列**实现优惠券秒杀  

> `全局ID生成器`:`符号位`1bit+`时间戳`31bit+`序列号`32bit支持每秒产生2^32个不同ID

### 1、解决多线程并发情况下库存超卖问题

> **`悲观锁`：插入数据**
>
>  悲观锁可以实现对于数据的串行化执行，比如syn，和lock都是悲观锁的代表，同时，悲观锁中又可以再细分为公平锁，非公平锁，可重入锁，等等
>
> **`乐观锁`(CAS)：乐观锁比较适合更新数据**
>
>   乐观锁：会有一个版本号，每次操作数据会对版本号+1，再提交回数据时，会去校验是否比之前的版本大1 ，如果大1

`悲观锁`(只用比较库存是否大于0)：

```java
boolean success = seckillVoucherService.update()
            .setSql("stock= stock -1")
            .eq("voucher_id", voucherId).update().gt("stock",0); //where id = ? and stock > 0
```

📕：**针对cas中的自旋压力过大，我们可以使用Longaddr这个类去解决**

### 2、一人一单问题-悲观锁

使用锁过程中，控制**锁粒度** 是一个非常重要的事情

> 改进流程：
>
> 1. 一开始封装了一个createVoucherOrder方法，同时为了确保他线程安全，`在方法上添加了一把synchronized 锁` -> `锁的粒度太粗`
>    - `public synchronized Result createVoucherOrder(Long voucherId)`
> 2. 降低锁的粒度
>    - Long userId = UserHolder.getUser().getId();
>      `synchronized(userId.toString().intern()){……}`
> 3. 新问题：`当前方法被spring的事务控制`，如果你`在方法内部加锁`，可能会导致当前方法`事务还没有提交`，但是`锁已经释放`也会导致问题；->选择将当前方法整体包裹起来，确保事务不会出现问题
> 4. 需要获得原始的事务对象， 来操作事务

### 3、集群环境下的并发问题

`模拟`：

- 将服务启动两份（Application1 Application2），端口分别为`8081和8082`
- 修改nginx的conf目录下的nginx.conf文件，`配置反向代理和负载均衡`：
  - ![image-20220824182638574](D:\算法Typora\picture\image-20220824182638574.png)

需要`分布式锁`来解决：

- 满足分布式系统或`集群模式下多进程可见并且互斥的锁`；

分布式锁需要满足什么条件：

- `可见性`：多个线程都能看到相同的结果，多个进程之间都能感知到变化的意思
- `互斥`：互斥是分布式锁的最基本的条件，使得程序串行执行
- `高可用`：程序不易崩溃，时时刻刻都保证较高的可用性
- `高性能`：由于加锁本身就让性能降低，所有对于分布式锁本身需要他就**较高的加锁性能和释放锁性能**
- `安全性`：安全也是程序中必不可少的一环

常见分布式锁：

- 数据库锁：利用mysql本身的互斥锁机制
- `基于Redis的分布式锁`：利用setnx互斥命令
- 基于ZooKeeper的分布式锁：Netflix的Curator（ZooKeeper客户端的封装）

### 4、Redis实现分布式锁核心思路

- 获取锁：
  - 利用redis 的`setNx` 方法，同时`增加过期时间`，防止死锁;但有了过期时间之后，`可能出现误删别人锁的问题`

```java
    // 获取锁
    Boolean success = stringRedisTemplate.opsForValue()
            .setIfAbsent(KEY_PREFIX + name, threadId + "", timeoutSec, TimeUnit.SECONDS);
```

- 释放锁：使用Lua脚本（判断）因为`拿锁，比锁，删锁`要具有原子性

​	1、获取锁中的线程标示

​	2、判断是否与指定的标示（当前线程标示）一致（）

​	3、`如果一致则释放锁（删除）`

​	4、如果不一致则什么都不做

```java
-- 这里的 KEYS[1] 就是锁的key，这里的ARGV[1] 就是当前线程标示
-- 获取锁中的标示，判断是否与当前线程标示一致
if (redis.call('GET', KEYS[1]) == ARGV[1]) then
  -- 一致，则删除锁
  return redis.call('DEL', KEYS[1])
end
-- 不一致，则直接返回
return 0
```

- `RedisTemplate`中，可以`利用execute方法去执行lua脚本`

```java
private static final DefaultRedisScript<Long> UNLOCK_SCRIPT;
    static {
        UNLOCK_SCRIPT = new DefaultRedisScript<>();
        UNLOCK_SCRIPT.setLocation(new ClassPathResource("unlock.lua"));
        UNLOCK_SCRIPT.setResultType(Long.class);
    }

public void unlock() {
    // 调用lua脚本
    stringRedisTemplate.execute(
            UNLOCK_SCRIPT,
            Collections.singletonList(KEY_PREFIX + name),
            ID_PREFIX + Thread.currentThread().getId());
}
```

### 5、基于Redisson实现分布式锁

`基于setnx实现的分布式锁存在下面的问题：`

**`重入问题`**：`获得锁的线程可以再次进入到相同的锁的代码块中`，`可重入锁的意义在于防止死锁`，比如HashTable这样的代码中，他的方法都是使用synchronized修饰的，假如他在一个方法内，调用另一个方法，那么此时如果是不可重入的，不就死锁了吗？所以可重入锁他的主要意义是防止死锁，我们的`synchronized和Lock锁都是可重入`的。

**`不可重试`**：是指目前的分布式只能尝试一次，我们认为合理的情况是：当`线程在获得锁失败后，他应该能再次尝试获得锁。`

**`超时释放`：**我们在加锁时增加了过期时间，这样的我们可以防止死锁，但是如果`卡顿的时间超长`，虽然我们采用了lua表达式防止删锁的时候，误删别人的锁，但是毕竟没有锁住，有安全隐患

**`主从一致性`：** 如果Redis提供了主从集群，当我们向集群写数据时，主机需要异步的将数据同步给从机，而万一在同步过去之前，`主机宕机了，就会出现死锁问题`。

📕：Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅`提供了一系列的分布式的Java常用对象`，还`提供了许多分布式服务`，其中就包含了各种分布式锁的实现。（`MutiLock锁实现主从`：只要有一个节点拿不到，都不能算是加锁成功）

**步骤：**`引入依赖 -> 配置Redisson客户端 -> 创建RedissonClient对象`

```java
@Configuration
public class RedissonConfig {

    @Bean
    public RedissonClient redissonClient(){
        // 配置
        Config config = new Config();
        config.useSingleServer().setAddress("redis://192.168.150.101:6379")
            .setPassword("123321");
        // 创建RedissonClient对象
        return Redisson.create(config);
    }
}
```

`->创建锁对象`：`RLock lock = redissonClient.getLock("lock:order:" + userId);`

`->获取锁对象`:`boolean isLock = lock.tryLock();`

原理：

- `Lock锁`中，他是借助于底层的`一个voaltile的一个state变量`来记录重入的状态的；
- 在`redission`中，`采用hash结构用来存储锁`，其中大key表示表示这把锁是否存在，用小key表示当前这把锁被哪个线程持有；

### 6、用消息队列实现异步秒杀

`优化方案`：我们`将耗时比较短的逻辑判断放入到redis中`，`比如是否库存足够，比如是否一人一单`，这样的操作，只要这种逻辑可以完成，就意味着我们是一定可以下单完成的，我们只需要进行快速的逻辑判断，根本就`不用等下单逻辑走完`，我们`直接给用户返回成功`， `再在后台开一个线程，后台线程慢慢的去执行queue里边的消息`，这样程序不就超级快了吗？而且也不用担心线程池消耗殆尽的问题，因为这里我们的程序中并没有手动使用任何线程池，当然这里边有`两个难点`

`第一个难点`是我们怎么`在redis中去快速校验一人一单，还有库存判断` ->**Lua脚本**

`第二个难点`是由于我们校验和tomct下单是两个线程，那么我们`如何知道到底哪个单他最后是否成功`，或者是下单完成，为了完成这件事我们在redis操作完之后，我们会将一些信息返回给前端，同时也会把这些信息丢到异步queue中去，后续操作中，可以通过这个id来查询我们tomcat中的下单逻辑是否完成了。

**方案步骤：**

* 新增秒杀优惠券的同时，将`优惠券信息保存到Redis中`

* 基于`Lua脚本`，判断秒杀库存、一人一单，决定用户是否抢购成功

* 如果抢购成功，`将优惠券id和用户id封装后存入阻塞队列`

* `开启线程任务`，不断从阻塞队列中获取信息，实现`异步下单功能`

![image-20220824234151112](D:\算法Typora\picture\image-20220824234151112.png)

基于Redis实现三种`消息队列`（最简单模型：`生产者 + MQ +消费者`）；现成的比如kafka，rabbitmq

- `基于List`：`LPUSH 结合 BRPOP`或者 `RPUSH 结合 BLPOP`来实现->`无法避免消息丢失 + 只支持单消费者`
- `基于PubSub发布订阅`:消费者可以订阅一个或多个channel，生产者向对应channel发送消息后，所有订阅者都能收到相关消息。->`不支持数据持久化+消息堆积有上限，超出时数据丢失`
- `基于Stream`:Stream 是 Redis 5.0 引入的一种新数据类型，可以实现一个功能非常完善的消息队列。
  - 发送消息：`XADD users * name jack age 21`
  - 读取消息：`XREAD COUNT 1 STREAMS users 0` (0->从第一个消息开始)
  - `XREAD阻塞`方式：`XREAD COUNT 1 BLOCK 1000 STREAMS users $`(**$->从第一个消息开始)**->`每次读最新有消息漏读的风险`
  - `消费者组（Consumer Group）`：将多个消费者划分到一个组中，监听同一个队列
    - 创建消费者组：`XGROUP CREATE key groupName ID [MKSTREAM]`

综上：`选择基于Redis的Stream消费者组`实现异步下单：

![image-20220825141044762](D:\算法Typora\picture\image-20220825141044762.png)

* `创建一个Stream类型的消息队列`，名为stream.orders
* `修改之前的秒杀下单Lua脚本`，在认定有抢购资格后，`直接向stream.orders中添加消息`，内容包含voucherId、userId、orderId
* 项目启动时，`开启一个线程任务，尝试获取stream.orders中的消息，完成下单`

## 达人探店

基于List来完成点赞列表的操作，同时基于SortedSet来完成点赞的排行榜功能

`点赞`：

- 同一个用户只能点赞一次，再次点击则取消点赞；
- 给`Blog类中添加一个isLike字段`，标示是否被当前用户点赞
- 修改点赞功能，`利用Redis的set集合判断是否点赞过`，未点赞过则点赞数+1，已点赞过则点赞数-1

`排行榜`：

- `Set<String> top5 = stringRedisTemplate.opsForZSet().range(key, 0, 4);`

```java
@Override
public Result queryBlogLikes(Long id) {
    String key = BLOG_LIKED_KEY + id;
    // 1.查询top5的点赞用户 zrange key 0 4
    Set<String> top5 = stringRedisTemplate.opsForZSet().range(key, 0, 4);
    if (top5 == null || top5.isEmpty()) {
        return Result.ok(Collections.emptyList());
    }
    // 2.解析出其中的用户id
    List<Long> ids = top5.stream().map(Long::valueOf).collect(Collectors.toList());
    String idStr = StrUtil.join(",", ids);
    // 3.根据用户id查询用户 WHERE id IN ( 5 , 1 ) ORDER BY FIELD(id, 5, 1)
    List<UserDTO> userDTOS = userService.query()
            .in("id", ids).last("ORDER BY FIELD(id," + idStr + ")").list()
            .stream()
            .map(user -> BeanUtil.copyProperties(user, UserDTO.class))
            .collect(Collectors.toList());
    // 4.返回
    return Result.ok(userDTOS);
}
```

## 好友关注

### 1、基于Set集合的关注、取消关注

`获取登录用户 -> 判断到底是关注还是取关 -> 进行关注或取关`

`判断`：

```java
@Override
public Result isFollow(Long followUserId) {
        // 1.获取登录用户
        Long userId = UserHolder.getUser().getId();
        // 2.查询是否关注 select count(*) from tb_follow where user_id = ? and follow_user_id = ?
        Integer count = query().eq("user_id", userId).eq("follow_user_id", followUserId).count();
        // 3.判断
        return Result.ok(count > 0);
    }
```

`关注`：

```java
        if (isFollow) {
            // 2.关注，新增数据
            Follow follow = new Follow();
            follow.setUserId(userId);
            follow.setFollowUserId(followUserId);
            boolean isSuccess = save(follow);

        } 
```

`取关：`

```java
		else {
            // 3.取关，删除 delete from tb_follow where user_id = ? and follow_user_id = ?
            remove(new QueryWrapper<Follow>()
                    .eq("user_id", userId).eq("follow_user_id", followUserId));

        }
        return Result.ok();
```

### 2、共同关注（set集合中，有交集并集补集的api）

`把两人的关注的人分别放入到一个set集合中`，然后再通过api去查看这两个set集合中的`交集数据`

- 求交集:`stringRedisTemplate.opsForSet().intersect(key, key2);`

- 解析id集合:`List<Long> ids = intersect.stream().map(Long::valueOf).collect(Collectors.toList());`

- 查询用户:

  ```java
      List<UserDTO> users = userService.listByIds(ids)
              .stream()
              .map(user -> BeanUtil.copyProperties(user, UserDTO.class))
              .collect(Collectors.toList());
      return Result.ok(users);
  ```

📕：`利用stream流读取数据`：（`迭代器结合Lambda表达式`）

``` java
mylist.stream()
    .map(myfunction->{
        return item;
    }).collect(Collectors.toList());

```

说明：**`steam()`:把一个源数据，可以是集合，数组，I/O channel， 产生器generator 等，`转化成流`；`map()`:用于`映射每个元素到对应的结果`；`Collectors()`: 类实现了很多`归约操作`，例如将流`转换成集合和聚合元素`。`Collectors 可用于返回列表或字符串`**

## 附近的商户

我们利用Redis的GEOHash来完成对于地理坐标的操作

`Redis在3.2版本中加入了对GEO的支持`->基于`Sorted Set`实现

- 类型相同的商户作为同一组，以typeId为key存入同一个GEO集合中
- `Redis 6.2提供的GEOSEARCH命令`
- `GEOSEARCH key BYLONLAT x y BYRADIUS 10 WITHDISTANCE`
- 经度的范围是[-180,180]，纬度的范围是[-90,90];先对经度和纬度分别进行GeoHash编码，然后再合并为一个编码值;通过N次的分区将其编码为一个N位的二进制值；
- 最终编码值的长度是2N，其中偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值（从0开始计数，0为偶数），示意图如下：

```java
        // 3.查询redis、按照距离排序、分页。结果：shopId、distance
        String key = SHOP_GEO_KEY + typeId;
        GeoResults<RedisGeoCommands.GeoLocation<String>> results = stringRedisTemplate.opsForGeo() // GEOSEARCH key BYLONLAT x y BYRADIUS 10 WITHDISTANCE
                .search(
                        key,
                        GeoReference.fromCoordinate(x, y),
                        new Distance(5000),
                        RedisGeoCommands.GeoSearchCommandArgs.newGeoSearchArgs().includeDistance().limit(end)
                );
```

## UV统计

使用 `HyperLogLog` 实现 UV 统计  

- Hyperloglog(HLL)是从Loglog算法派生的概率算法，用于确定非常大的集合的基数，而不需要存储其所有值。相关算法原理参考：https://juejin.cn/post/6844903785744056333#heading-0
- Redis中的HLL是`基于string结构实现`的，单个HLL的内存**永远小于16kb**，**内存占用低**的令人发指！作为代价，其测量结果是概率性的，**有小于0.81％的误差**。不过对于UV统计来说，这完全可以忽略。

![image-20220825144654088](D:\算法Typora\picture\image-20220825144654088.png)

步骤：

- 先用 `INFO MEMORY`查看并记录redis内存使用情况，方便后续对比；
- `插入100万条数据，约占了14kb`
- count = 997593

## 补充问题：

### **Q：为什么建议`使用sl4j`，不建议使用log4j**

​	SLF4J(Simple logging Facade for Java)不是一个真正的日志实现，而**是一个抽象层**（ abstraction layer），它允许你在后台使用任意一个日志类库。如果是在编写供内外部都可以使用的API或者通用类库，那么你真不会希望使用你类库的客户端必须使用你选择的日志类库。

​	优点1：**使用SLF4J写日志语句的主要出发点是使得你的`程序独立于任意特定的日志类库`，依赖于特定类可能需要不同与你已有的配置，并且导致更多维护的麻烦。**

​	优点2：`占位符`(place holder)，提高了代码可读性。

​	优点3：通过使用SLF4J的日志方法，可以`延迟构建日志信息`（Srting）的开销，直到真正需要，这对于内存和CPU都是高效的；

# Nginx

## **1、什么是Nginx？**

​	Nginx是一个 轻量级/高性能的**反向代理Web服务器**，用于 HTTP、HTTPS、SMTP、POP3 和 IMAP 协议。他实现非常高效的**反向代理**、**负载平衡**，他可以处理2-3万并发连接数，官方监测能支持5万并发，现在中国使用nginx网站用户有很多，例如：新浪、网易、 腾讯等。

## **2、Nginx应用场景？**

- http服务器。Nginx是一个http服务可以独立提供http服务。可以做**网页静态服务器**。
- 虚拟主机。可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。
- 反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。
- nginz 中也可以配置安全管理、比如可以使用Nginx搭建API接口网关,对每个接口服务进行拦截。
- **静态资源放到 Nginx** 中，动态资源转发到 Tomcat 服务器中



## 3、**Nginx 是如何实现高并发的？**

- 异步非阻塞工作方式:利用等待网络传输的时间将线程空闲出来；

- 每进来一个 request ，会有一个 worker 进程去处理。但不是全程的处理，处理到什么程度呢？**处理到可能发生阻塞的地方;**
- web server 的工作性质决定了**每个 request 的大部份生命都是在网络传输中**，实际上花费在 server 机器上的时间片不多。这是几个进程就解决高并发的秘密所在。
- webserver 刚好属于网络 **IO 密集型**应用，不算是计算密集型。
- **异步，非阻塞，使用 epoll** ，和大量细节处的优化。

## 4、正向代理、反向代理，反向代理的优点？

- 正向代理：代理端代理的是客户端；-> 将客户端的请求转发给原始服务器
- 反向代理：代理端代理的是服务端。->

- 反向代理的优点：反向代理服务器可以**隐藏源服务器的存在和特征**。它充当互联网云和web服务器之间的中间层。这对于安全方面来说是很好的

## 5、负载均衡怎么实现，有哪些策略？

当用户访问时，先访问到一个**转发服务器**，再由转发服务器将访问分发到压力更小的服务器

- **轮询(默认)**：每个请求**按时间顺序逐一分配**到不同的后端服务器，如果后端某个服务器宕机，能自动剔除故障系统；
- **权重 weight**：weight的值越大，分配到的访问概率越高；
- **ip_hash**：每个请求按访问IP的哈希结果分配，使来自**同一个IP的访客固定访问一台后端服务器**，并且可以有效解决动态网页存在的session共享问题；
- **fair(第三方插件)**：安装upstream_fair模块。fair算法可以根据页面大小和加载时间长短智能地进行负载均衡，响应时间短的优先分配。
- **url_hash(第三方插件)**:

## 6、**cookie和session区别？**

#### 共同：

存放用户信息。存放的形式：key-value格式 变量和变量内容键值对。

#### 区别：

cookie：

- 存放在客户端浏览器
- 每个域名对应一个cookie，不能跨跃域名访问其他cookie
- 用户可以查看或修改cookie
- http响应报文里面给你浏览器设置
- 钥匙（用于打开浏览器上锁头）

session:

- 存放在服务器（文件，数据库，redis）
- 存放敏感信息
- 锁头

# ZooKeeper

## 1、原理

- 说明：Curator是ZooKeeper客户端的封装。
- 原理：
  - ZooKeeper 分布式锁是基于 `临时顺序节点`(EPHEMERAL_SEQUENTIAL) 来实现的，`锁可理解为 ZooKeeper 上的一个节点`，当`需要获取锁`时，就在这个`锁节点下创建一个临时顺序节点`。
  - 当存在多个客户端同时来获取锁，就`按顺序依次创建多个临时顺序节点`，但`只有排列序号是第一的那个节点能获取锁成功`，其他节点则按顺序分别`监听前一个节点的变化`，当被监听者释放锁时，监听者就可以马上获得锁。
  - 节点的临时性特性保证了锁持有者与ZooKeeper断开时强制释放锁。
- 优点：节点的`SEQUENTIAL特性``避免了锁释放时出现的惊群效应`。



# 场景题

## 1、设计一个Java对象的序列化：

`实现序列化和反序列化的方式`则是通过俩类实现：

**序列化**:`ObjectOutputStream`

**反序列化**:`ObjectInputStream`

```java
 import java.io.*;
 public class JavaIODenmo {
     //定义序列化的文件位置
     private static final File SAVE_FILE = new File("D:"+File.separator+"serializableText");
     public static void main(String[] args) throws Exception {
         saveObject(new Member("xbhog",18));
         System.out.println(LoadObject());
     }
     private static void saveObject(Object object) throws Exception {
         OutputStream fileOutputStream = new FileOutputStream(SAVE_FILE);
         ObjectOutputStream stream = new ObjectOutputStream(fileOutputStream);
         stream.writeObject(object);  //序列化
         stream.close();
     }
     private static Object LoadObject() throws Exception {
         /*实例化InputStream */
         InputStream inputStream = new FileInputStream(SAVE_FILE);
         ObjectInputStream stream = new ObjectInputStream(inputStream);
         Object o = stream.readObject();  //反序列化
         stream.close();
         return o;
     }
 }
```

## 2、请输出两个字符串a和b相减的结果?

（a>b，a和b的字符串长度介于1~50之间）。例：输入a:“99999”,b=“99998”，输出：“1”

```java
import java.math.BigInteger;
public class Main {
    public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException {
        String s1 = new String("9999999999999999999999999999999999999999999999999");
        //String s2 = new String("9999999999999999999999999999999999999999999999998");
        String s2 = new String("1");
        BigInteger bigInteger1 = new BigInteger(s1);
        BigInteger bigInteger2 = new BigInteger(s2);
        BigInteger subtract = bigInteger1.subtract(bigInteger2);
        System.out.println(subtract);
    }
}
```



# 算法

# 简历

###                        📧wubin557922@163.com · 📞 (+86) 151-1752-0888 ·

## 🎓教育背景

### 西安电子科技大学, 西安, 陕西 2020 –至今

#### 在读学业硕士 人工智能学院 - 控制科学与工程 研究方向：基于深度学习的遥感图像实例分割

#### 研一均分 (88.03) 预计 2023 年 6 月毕业

### 西安电子科技大学, 西安, 陕西 2016 – 2020

#### 学士 人工智能学院 - 智能科学与技术 ( 推免 )

#### 平均学分绩点 :3.7 英语 - 六级

## 📕论文/获奖/专利

- 论文 : IGARSS 2021—— Polarmetric Sar Image Classification Based On Edge-Aware Dual Branch Fully
    Convolution Network
- 获奖: 第十二届“ CETC-10通信杯”《基于深度学习的可见光遥感图像目标检测研究进展》, 第二名
- 获奖:20-21 年度校优秀研究生, 研究生一等学业奖学金, 优秀党员干部, 本科多次获得校级奖学金
- 专利: 基于神经网络结构搜索的遥感图像变化检测方法 , 专利号：202111515285.

## 📐IT技能
- 熟悉 Java 开发设计，熟练掌握多线程、集合等基础类库；
- 熟悉 Mysql 数据库、分布式缓存 Redis 以及 Tomcat 服务器的使用；
- 了解 JVM 性能调优、常见 JVM 垃圾收集算法及常用 JVM 调优命令；
- 了解 SpringMVC，有一定的 JavaWeb 应用开发的经验，掌握常用的设计模式;
- 熟悉使用 Jmeter、Postman 并发场景测试工具；
- 熟悉 Maven，Idea ，Git，Xshell 等常用工具，Linux 系统常用操作命令；
- 专业领域熟悉基于深度学习的经典实例分割框架，pytorch 深度框架的使用。

## 🙌项目经历
### 基于 Redis 的社交类点评项目 2021 年 9 月– 2021 年 12 月

#### 个人项目 主要开发者

使用Nginx 和Tomcat完成以社交平台为核心的面向项目部署，丰富利用Redis的各知识框架实现多种
功能集合

- 通过Redis 应用共享session实现短信登录，并使用双拦截器改进登录流程；
- 实现商户查询缓存，同时通过代码实现模拟并解决缓存穿透、缓存雪崩、缓存击穿的问题；
- 利用Redis 计数器、Lua 脚本、分布式锁和消息队列实现优惠券秒杀；
- 实现基于 List 的点赞列表和基于SortedSet的点赞排行榜；
- 基于Set 集合的关注、取关、共同关注的功能；
- 利用Redis 的GeoHash实现查询附近的商户功能；以及使用HyperLogLog实现UV 统计。

### 机载场景自适应模型定制技术 2020 年 12 月– 2021年 12 月

#### 研究所合作项目 算法框架搭建
#### 项目简介
通过直接轻量化模型定制以及先模型定制后压缩两种技术思路，建立深度神经网络结构的自适应优化模型及相应的学习算法，实现网络结构的自动定制和对机载场景数据的稳定、快速自动处理，为不同场景下的深度学习模型高效应用提供技术支撑。

#### 基于通道剪枝的轻量化行人重识别技术

- 实现基于通道剪枝的轻量化行人重识别技术，将这一技术应用于无人机需要重型网络达到识别精度的场景，能够大大降低模型的复杂度和计算量，使得重型网络能搭载到无人机上；
- 为行人重识别设计了一种基于特征编码的相似度评分架构；
- 能够在降低模型70%通道数的情况下基本保持重识别精度在85%；
- 实现将该技术移植到Jetson NX嵌入式板卡，完成INT16到INT8量化。

#### 基于神经网络结构搜索的轻量化无人机目标检测技术

- 实现基于one-shot的结构搜索方法并应用于无人机目标检测任务，重新定制轻量化主干网络，在
    保证较高精度的前提下，降低模型参数和计算量并提高检测速度；
- 构建超网络结构并预训练出 4 种不同的轻量化网络结构块；
- 通过搜索实现最佳子网络结构从而实现性能更优的无人机目标检测；
- 相较于同等算法，本技术在减少50%参数量的情况下精度提高10%；

### 无人机实时轻量化智能自主决策技术 2021 年 12 月–至今

#### 研究所合作项目 算法框架搭建

#### 项目简介
针对目前无人机战斗获取战场态势、自主决策慢的应用弊端，围绕目标快速识别及快速决策的需求，开展无人机感知战场态势、自主决策的轻量化技术研究。

#### 基于强化学习的无人机自主机动决策技术

-  实现基于DQN的无人机机动决策，可达到连续决策的效果；

- 设计了更有效的回报函数，包含距离回报、偏转角回报以及高度回报；

- 根据无人机机动属性及回报奖励设计无人机机动策略；

- 实现10ms内完成一次决策，且实现多对多打击任务。

## 🏊‍其他

- 能够不断更新专业领域前沿知识，坚持阅读顶刊顶会；

-  生活积极乐观，喜欢运动。





